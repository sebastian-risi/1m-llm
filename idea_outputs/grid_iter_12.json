{
  "scores": [
    [
      0.3996828221348827,
      0.0,
      0.8433943074655427,
      0.7847562077664854,
      0.7250000000000001,
      0.7409545604758758,
      0.6637620046211522,
      0.0,
      0.8753223684210527,
      0.8262908929575273
    ],
    [
      0.5743428195488722,
      0.4080776325521335,
      0.807763255213347,
      0.8389057524001601,
      0.8101075824692797,
      0.7854144802420576,
      0.0,
      0.8125,
      0.0,
      0.6736208779534252
    ],
    [
      0.7857857142857143,
      0.7987019431643625,
      0.0,
      0.0,
      0.0,
      0.0,
      0.8125,
      0.694276216989748,
      0.7239778571428571,
      0.7035410169461747
    ],
    [
      0.7912140921136576,
      0.0,
      0.0,
      0.8375,
      0.8387475490196079,
      0.7372301401869159,
      0.684964110314398,
      0.875,
      0.0,
      0.7981233169462116
    ],
    [
      0.6567272727272727,
      0.8176379726529688,
      0.5411670002171503,
      0.791270622895623,
      0.8167541208791209,
      0.82462378383769,
      0.6897579787234043,
      0.750279822378879,
      0.7359474111615932,
      0.0
    ],
    [
      0.0,
      0.65,
      0.0,
      0.8077292917956657,
      0.7649842735603188,
      0.8456118421052632,
      0.7659557391590964,
      0.0,
      0.7462767366243842,
      0.0
    ],
    [
      0.0,
      0.7648812171209948,
      0.7875000000000001,
      0.795375,
      0.8405406108533753,
      0.40845611842105267,
      0.7792779942751901,
      0.818271133245837,
      0.7315226894163385,
      0.7689530350923024
    ],
    [
      0.8125,
      0.0,
      0.7878931725990825,
      0.7916812409963986,
      0.690326928340615,
      0.7579507236622053,
      0.7950998574209996,
      0.0,
      0.8123389486741801,
      0.8381805555555555
    ],
    [
      0.0,
      0.6174185482109423,
      0.6898843602535745,
      0.0,
      0.7578421795647967,
      0.6877350359014044,
      0.8489950300256605,
      0.0,
      0.0,
      0.6941073747680891
    ],
    [
      0.7382468605743425,
      0.7382663043478261,
      0.7472829479437632,
      0.7192916666666667,
      0.7308784388544474,
      0.0,
      0.8693232836335899,
      0.6721932328363359,
      0.0,
      0.8625
    ]
  ],
  "last_updated": [
    [
      11,
      -1,
      11,
      12,
      1,
      5,
      10,
      -1,
      11,
      12
    ],
    [
      9,
      12,
      8,
      5,
      6,
      10,
      -1,
      10,
      -1,
      11
    ],
    [
      2,
      6,
      -1,
      -1,
      -1,
      -1,
      7,
      11,
      10,
      10
    ],
    [
      9,
      -1,
      -1,
      4,
      10,
      8,
      9,
      6,
      -1,
      8
    ],
    [
      4,
      8,
      10,
      5,
      4,
      11,
      3,
      6,
      11,
      -1
    ],
    [
      -1,
      7,
      -1,
      6,
      7,
      5,
      11,
      -1,
      12,
      -1
    ],
    [
      -1,
      12,
      3,
      3,
      9,
      8,
      6,
      10,
      12,
      12
    ],
    [
      1,
      -1,
      12,
      9,
      12,
      6,
      10,
      -1,
      7,
      4
    ],
    [
      -1,
      8,
      9,
      -1,
      7,
      9,
      6,
      -1,
      -1,
      10
    ],
    [
      11,
      3,
      11,
      2,
      5,
      -1,
      9,
      12,
      -1,
      1
    ]
  ],
  "ideas": [
    [
      "[NLP] Exploring the Impact of Personalized Narrative Generation on User Engagement in Simulation Environments",
      null,
      "[NLP] Contextual Sentiment Analysis of Social Media Posts for Mental Health Support\n\nThis research will develop a novel model for analyzing social media posts to identify patterns and sentiment associated with mental health struggles, using a transformer-based architecture. It will leverage a pre-trained model and fine-tune it on a dataset of publicly available social media content, focusing on identifying keywords and phrases indicative of distress. Evaluation will be based on accuracy in sentiment classification and the ability to detect emerging trends in mental health discussions.",
      "[Safety] Explainable AI for Autonomous Vehicles\n\nThis research will develop a framework for explaining the decisions made by autonomous vehicles, focusing on identifying the key factors influencing their actions and providing justifications for those decisions. The system will utilize attention mechanisms and rule-based reasoning to highlight the most relevant sensor data and contextual information driving the vehicle\u2019s behavior, enhancing transparency and trust. Data will include vehicle logs, sensor readings, and simulated driving scenarios. Evaluation will involve comparing the explanations provided by the framework with human judgments of reasonableness and safety.",
      "[Evaluation] Dynamic Attention Network for Visual Scene Understanding\n\nThis research explores a novel dynamic attention mechanism for visual scene understanding, aiming to improve performance on complex scenes with occlusions and varying object scales. The idea involves extending the standard self-attention mechanism to incorporate a \"contextual memory\" layer that dynamically adjusts the attention weights based on recent visual input. We will evaluate the network on a dataset of human-annotated scenes with varying levels of occlusion and object scale using metrics like Mean Intersection over Union (mIoU) and a custom metric measuring the accuracy of object segmentation.",
      "[NLP] Text-to-Image Style Transfer for Enhanced Narrative Generation\n\nThis project explores the use of a novel text-to-image style transfer technique to dynamically adjust the visual style of generated narratives, enhancing their emotional impact and reader engagement. The system will utilize a diffusion model fine-tuned on a dataset of emotionally-labeled stories, and will evaluate the generated narratives based on human ratings of emotional valence and narrative coherence.",
      "[NLP] Contextual Sentiment-Driven Narrative Coherence Enhancement\nThis project explores a method for enhancing the coherence of interactive narratives by dynamically adjusting the narrative style based on the user\u2019s emotional response to the story\u2019s content. The system will utilize a transformer model fine-tuned on user-generated stories, incorporating sentiment analysis to identify emotional peaks and valleys. Evaluation will be based on average user ratings and qualitative analysis of user responses.",
      null,
      "[ML] Adversarial Training for Robust Object Detection in Low-Light Conditions\n\nThis research focuses on developing robust object detection models that perform reliably in challenging low-light environments. We will explore adversarial training techniques to improve the model\u2019s resilience to noise and illumination variations, potentially enhancing performance in applications like autonomous driving or surveillance. Data will include a diverse set of images captured in varying lighting conditions, and evaluation will be based on mean Average Precision (mAP) across multiple low-light scenarios.",
      "[HCI] Dynamic Embodied Guidance System for Elderly Users\n\nThis research investigates the design and implementation of a dynamic, embodied guidance system for elderly users, leveraging a wearable device to provide subtle, real-time feedback on navigation and obstacle avoidance. The system will utilize a combination of inertial measurement units (IMUs) and visual cues to create a personalized and adaptive guidance experience, focusing on reducing falls and promoting independence. Evaluation will involve a series of controlled trials with elderly participants, measuring navigation accuracy, confidence, and fall risk reduction."
    ],
    [
      "[Cognitive Science] Investigating the Neural Correlates of Emotional Resonance in Virtual Companions\n\nThis research will explore the neural activity associated with emotional resonance experienced by users interacting with virtual companions, specifically focusing on the role of mirror neuron systems. I will use fMRI to examine how participants\u2019 brain activity changes when they receive feedback indicating the virtual companion\u2019s emotional state, and correlate these changes with subjective reports of emotional engagement. Data will include fMRI data, self-report questionnaires assessing emotional engagement, and measures of physiological responses (e.g., heart rate variability). Metrics will include accuracy of emotional state prediction and subjective ratings of emotional engagement.",
      "[Safety] Explainable AI for Automated Loan Applications",
      "[Evaluation] Federated Learning for Personalized Medical Diagnosis\n\nThis research will explore the feasibility and effectiveness of federated learning for training diagnostic models on medical data distributed across multiple hospitals. I will build a system that allows multiple hospitals to collaboratively train a diagnostic model without sharing their raw patient data, leveraging local model updates to improve overall accuracy. Data will include patient records, imaging data, and clinical notes, and evaluation will be based on diagnostic accuracy, sensitivity, and specificity across different hospitals.",
      "[NLP] Contextualized Sentiment Analysis with Visual Grounding\n\nThis research will develop a system that analyzes sentiment in text by combining contextual understanding with visual cues from an image. The system will use a transformer model to identify sentiment, but will also incorporate visual features (e.g., facial expressions, object recognition) to provide a richer understanding of the sentiment expressed. I will evaluate the system using a held-out dataset of text and images, measuring accuracy and F1-score on sentiment classification and visual similarity.",
      "[Vision]  Interactive Scene Graph Generation for Robotic Manipulation\n\nThis research explores a method for generating interactive scene graphs \u2013 representations of the environment that robots can use to plan and execute manipulation tasks \u2013 leveraging visual information and object properties. It will utilize a graph neural network to learn a representation of the scene, incorporating object attributes and spatial relationships, and then generate a sequence of actions that a robot can execute. Evaluation will be based on the success rate of successful manipulation tasks, measured by the number of successful grasp events and the time taken to complete the task.",
      "[ML] Personalized Recommendation Systems for Precision Agriculture using Satellite Imagery\n\nThis project aims to develop a system that leverages satellite imagery and machine learning to provide highly personalized recommendations for agricultural practices, optimizing crop yields and resource utilization. The system will utilize a convolutional neural network (CNN) trained on a large dataset of satellite imagery, incorporating spectral indices and object detection to identify areas of stress, nutrient deficiencies, and pest infestations. Evaluation will be based on yield improvements, resource savings (water, fertilizer), and the accuracy of recommendations compared to expert advice.",
      null,
      "[HCI] Dynamic UI Adaptation for Multi-Modal Navigation: Leveraging Eye-Tracking and Contextual Audio\n\nThis research investigates how dynamic UI adaptation can be implemented within a mobile navigation app to optimize user experience, particularly in complex or ambiguous environments. It will develop a system that adjusts the app\u2019s visual layout and audio cues based on real-time eye-tracking data and contextual audio cues (e.g., traffic noise, pedestrian presence) to reduce cognitive load and improve route adherence. Evaluation will involve measuring task completion rates, user error rates, and subjective user ratings of usability and comfort.",
      null,
      "[Safety] AI-Powered Predictive Hazard Detection in Public Spaces\n\nThis research explores the development of an AI system that analyzes video feeds from public spaces to predict and alert users to potential safety hazards \u2013 such as dropped objects, obscured pathways, or unusual activity \u2013 using object recognition and behavioral analysis. The system will leverage a combination of computer vision, natural language processing, and risk assessment algorithms to provide proactive warnings, improving situational awareness and reducing the risk of accidents. Evaluation will involve testing the system\u2019s accuracy in predicting hazards and measuring the effectiveness of the alerts in preventing incidents through a simulated public space environment."
    ],
    [
      "[NLP] Personalized Dialogue Style Analysis using Transformer Networks\n\nThis research explores the impact of dialogue style on user engagement and satisfaction in virtual assistants. I will develop a transformer-based model that analyzes user responses to virtual assistants, identifying distinct stylistic patterns (e.g., formal, informal, humorous) and correlating these patterns with user sentiment and task completion rates. Data will include a dataset of user-assistant interactions, labeled with stylistic features and user feedback. Evaluation will be based on user satisfaction scores and task completion time.",
      "[NLP] Contextual Sentiment Shift Detection in Conversational AI\n\nThis research will develop a model that analyzes the sentiment expressed within a conversation, identifying shifts in sentiment that indicate a user is becoming frustrated or dissatisfied with the AI's responses. I will build a model leveraging transformer networks to detect subtle changes in sentiment expressed through word choice, emoji usage, and conversational tone, and will evaluate performance using a held-out dataset of user-AI conversations labeled with sentiment scores.",
      null,
      null,
      null,
      null,
      "[Cognitive Science] Investigating the Impact of Episodic Memory Retrieval on Social Bias Amplification\n\nThis research explores how readily available episodic memories of specific social interactions can inadvertently amplify existing biases towards particular individuals, potentially leading to inaccurate judgments of trustworthiness or competence. Participants will be presented with a series of short, ambiguous social scenarios, and their responses will be analyzed to determine if retrieval of related memories significantly alters their subsequent judgments.  The study will utilize fMRI to examine neural activity associated with bias detection and consolidation.",
      "[HCI] Personalized Spatial Audio Feedback for Navigation Assistance\n\nThis research will develop a system that uses personalized spatial audio cues to provide real-time feedback to users navigating a mobile environment. The system will analyze the user\u2019s gaze and head movements to determine their preferred route and adjust the audio feedback accordingly, improving situational awareness and reducing cognitive load. Data will include eye-tracking data, user feedback (e.g., ratings of audio clarity), and a simulated environment with varying levels of complexity. Metrics will include task completion time, user satisfaction scores, and error rates.",
      "[Visualization] Procedural Texture Generation with Style Transfer and Reinforcement Learning for Low-Resolution Data\n\nThis research proposes a framework for generating high-quality textures from limited data using a combination of procedural techniques and reinforcement learning. The system will train a neural network to map a small set of input images (e.g., low-resolution scans) to a target texture, guided by a reinforcement learning agent that learns to optimize texture quality based on user feedback. Evaluation will be based on perceptual quality metrics (e.g., LPIPS) and the ability to generate textures that closely match the characteristics of provided reference images.",
      "[Vision] Personalized Emotional Response Generation through Visual Cue Integration\n\nThis research investigates the integration of visual cues \u2013 specifically facial expressions and body language \u2013 with a multimodal model to generate personalized emotional responses in interactive narratives. The model will learn to associate specific visual patterns with corresponding emotional states, allowing for dynamic adaptation of the narrative\u2019s tone and pacing based on the user\u2019s emotional state. Data will include a dataset of human interactions with narratives, annotated with emotional labels and corresponding visual cues. Evaluation will be based on user ratings of emotional engagement and narrative coherence."
    ],
    [
      "[NLP] Knowledge Graph-Enhanced Sentiment Analysis for Social Media\nThis research proposes a novel approach to sentiment analysis by integrating knowledge graphs to improve the accuracy and interpretability of models. The system will leverage Wikidata and other knowledge sources to provide contextualized sentiment information, enhancing the model\u2019s ability to understand nuanced user expressions. Evaluation will be based on F1-score and a metric assessing the coherence of the model\u2019s sentiment predictions with the knowledge graph\u2019s representation of the social media context.",
      null,
      null,
      "[HCI] Personalized Embodied Feedback for Navigation Assistance\n\nThis research explores the integration of haptic feedback into a mobile navigation app to provide users with more intuitive and personalized guidance. We will develop a system that uses subtle vibrations to indicate the direction of movement and potential obstacles, tailored to the user\u2019s gait and preferred navigation style. The system will be evaluated through user studies measuring task completion time, error rates, and subjective ratings of comfort and ease of use. Metrics will include frequency of successful navigation and user reported feelings of confidence.",
      "[NLP] Sentiment-Aware Dialogue Summarization for User Engagement\n\nThis research investigates a method for automatically generating concise summaries of long dialogue transcripts, incorporating sentiment analysis to highlight user engagement and potential areas of interest. We will develop a model that not only extracts key events but also assesses the emotional tone of the user's responses, providing a richer understanding of their satisfaction and intent. Data: Collection of dialogue transcripts from a simulated user base. Evaluation: ROUGE scores, human evaluation of summary quality (engagement, clarity).",
      "[Safety] Explainable AI for Automated Loan Denial Decisions\n\nThis research focuses on developing methods to provide transparency and justification for automated loan denial decisions, addressing concerns about fairness and potential discrimination. We will build a system that analyzes loan application data (including applicant demographics, credit history, and income) and generates a detailed, human-readable explanation of the factors contributing to the denial, using techniques like rule-based reasoning and potentially incorporating fairness metrics. Evaluation will involve comparing the system\u2019s explanations to those provided by human loan officers and assessing their accuracy and comprehensibility.",
      "[NLP] Personalized Narrative Generation for User Engagement\n\nThis research will develop a system that generates unique, personalized narratives tailored to individual user preferences and emotional states, using a combination of sentiment analysis and reinforcement learning. The system will analyze user activity and emotional responses to dynamically adjust the narrative's tone, complexity, and content, aiming to increase user engagement and satisfaction.",
      "[Vision] Visual Grounding for Dialogue: Exploring Contextualized Visual Anchors for Conversational Agents. This research will develop a system that allows conversational agents to reliably ground their responses in visual context \u2013 specifically, using a small set of pre-defined visual anchors (e.g., a specific object, a room scene) to improve coherence and understanding of user intent. We will evaluate the system using a user study where participants are asked to complete tasks requiring visual reasoning, measuring accuracy and perceived coherence.",
      null,
      "[NLP] Contextual Sentiment Analysis of Scientific Literature for Accelerated Discovery\n\nThis research investigates the use of a fine-tuned transformer model to automatically analyze scientific publications and identify key concepts, relationships, and potential research directions. The model will be trained on a corpus of peer-reviewed papers across various disciplines, focusing on identifying emerging themes and highlighting areas of active investigation. Evaluation will be based on precision and recall of relevant concepts, as well as the coherence and readability of the identified insights."
    ],
    [
      "[NLP] Explainable Sentiment Analysis with Attention-Based Graph Embedding\nThis research explores using attention mechanisms to enhance explainability in sentiment analysis models, particularly by incorporating graph embeddings derived from knowledge graphs. The model will be trained on a dataset of social media posts, and explainability will be evaluated using methods like SHAP and LIME, focusing on identifying the most influential entities driving sentiment predictions.",
      "[HCI] Personalized Embodied Navigation Assistance for Elderly Users\n\nThis research will develop a mobile application that uses computer vision and natural language processing to provide personalized navigation assistance to elderly users, leveraging their preferred routes and spatial awareness. The app will utilize a combination of visual landmark recognition and conversational AI to offer step-by-step instructions and anticipate potential obstacles, incorporating user feedback to continuously improve the experience. Evaluation will be based on task completion rate, user satisfaction (measured through surveys), and fall risk reduction.",
      "[Cognitive Science] Investigating the Impact of Implicit Social Evaluation on Episodic Memory Consolidation \u2013 A Longitudinal Study\n\nThis research will conduct a longitudinal study examining the impact of repeated implicit social evaluation on episodic memory consolidation. We will use fMRI to assess neural activity during simulated social interactions, tracking changes in brain regions associated with reward processing and social cognition. The goal is to determine if repeated implicit evaluations of a person\u2019s behavior strengthen the encoding of relevant episodic memories, leading to improved recall and a more robust understanding of how social evaluation shapes memory formation. Data will include behavioral measures of social evaluation (e.g., facial expressions, verbal comments) and fMRI data capturing neural responses to simulated social interactions.",
      "[NLP] Sentiment-Aware Dialogue Generation for Crisis Support\n\nThis research aims to develop a dialogue agent that dynamically adjusts its response style based on the user\u2019s expressed emotional state, improving the effectiveness of crisis support conversations. We will utilize a transformer model fine-tuned on a dataset of crisis conversations and incorporate a sentiment analysis module to monitor the user\u2019s emotional cues. Evaluation will be based on user satisfaction scores and a measure of crisis resolution success.",
      "[NLP] Contextualized Dialogue State Tracking with Attention\n\nThis research explores the use of attention mechanisms to improve the contextual understanding of dialogue states within a large language model. We will develop a system that dynamically weights different parts of the dialogue history based on their relevance to the current turn, enhancing the model\u2019s ability to track user goals and intentions across longer conversations. Data will be collected through a series of simulated dialogues, and evaluation will be based on task completion rate and user satisfaction scores.",
      "[Vision] Embodied Dialogue Understanding with Action Prediction\n\nThis research explores the integration of action prediction models with visual grounding to enhance dialogue understanding, particularly in scenarios involving physical actions or interactions. We will train a model to predict the user\u2019s intended action based on visual cues, allowing the system to better anticipate and respond to their actions, leading to more natural and efficient conversations. Evaluation will be based on metrics like task completion rate and user satisfaction.",
      "[NLP] Contextualized Dialogue State Tracking with Attention\n\nThis research explores a novel approach to dialogue state tracking that leverages attention mechanisms to dynamically weight the importance of different contextual cues during response generation. It builds upon the existing work of incorporating visual cues into dialogue understanding, but instead of relying solely on facial expressions, it focuses on analyzing body posture and gestures to refine the model\u2019s understanding of the user\u2019s emotional state and intent. We will evaluate the model\u2019s performance on a benchmark dataset of multi-turn conversations, measuring metrics such as coherence, relevance, and user satisfaction.",
      "[NLP] Personalized Knowledge Graph Construction for Scientific Discovery\n\nThis research will develop a system that automatically constructs personalized knowledge graphs for researchers based on their current research interests and publications. The system will leverage a combination of text mining, citation analysis, and knowledge graph embedding techniques to identify relevant entities and relationships, and then iteratively refine these graphs to reflect the researcher\u2019s evolving understanding of the field. We will evaluate the quality of the generated knowledge graphs using metrics such as coverage, coherence, and novelty, and assess their impact on research productivity through user surveys.",
      "[NLP] Dynamic Persona Generation for Counter-Narrative Response in Social Media \u2013 A Multi-Agent System\nThis research proposes a system that utilizes a multi-agent approach to generate dynamic personas for counter-narratives in social media, responding to user-generated content. The system will leverage a large dataset of social media posts and automatically generate personas representing opposing viewpoints, then dynamically adjust these personas based on user engagement to create a more effective counter-narrative. Evaluation will be based on user sentiment analysis of the counter-narrative and a measure of engagement (e.g., shares, comments).",
      null
    ],
    [
      null,
      "[Safety] Algorithmic Bias Detection in Autonomous Vehicle Perception Systems\n\nThis research will develop a novel framework for detecting and quantifying algorithmic bias in pedestrian detection models used by autonomous vehicles. The framework will leverage a combination of adversarial training and explainable AI (XAI) techniques to identify subtle biases that might lead to disproportionate risk assessments for certain demographic groups. Data will include a diverse set of pedestrian datasets augmented with simulated adversarial examples generated using a modified adversarial attack algorithm. Evaluation will be based on metrics like false positive rate and disparate impact analysis, focusing on the fairness of risk assessment across different demographic groups.",
      null,
      "[NLP] Visual-Textual Sentiment Alignment for Enhanced Dialogue Quality\n\nThis research explores how visual cues (e.g., facial expressions in videos, objects in images) can be integrated with textual dialogue to improve the coherence and emotional resonance of conversations. We will develop a model that analyzes both the text and visual data to predict the user's emotional state and adjust the dialogue accordingly, leveraging a transformer model trained on paired visual and textual data. We will evaluate the model\u2019s performance using metrics like coherence score and user ratings of emotional engagement.",
      "[NLP] Knowledge Graph Completion with Adversarial Training for Enhanced Reasoning\n\nThis research explores the use of adversarial training to improve the accuracy and robustness of knowledge graph completion. We will train a model to predict missing relationships between entities in a knowledge graph, incorporating an adversarial component that encourages the model to generate plausible but incorrect completions. We will evaluate the model on benchmark knowledge graphs and human-annotated datasets using metrics like accuracy and consistency.",
      "[NLP] Contextualized Sentiment Analysis for Scientific Report Generation\n\nThis research aims to develop a system that automatically generates concise and informative summaries of scientific reports, incorporating contextual sentiment analysis to ensure the report accurately reflects the author's intended message and audience. We will use a transformer-based model fine-tuned on a dataset of scientific reports and their associated sentiment scores. Evaluation will be based on human assessment of report clarity, accuracy, and persuasiveness, as well as automated metrics like ROUGE and BLEU for summarization quality.",
      "[NLP] Explainable Reinforcement Learning for Robotic Manipulation\n\nThis research investigates using attention mechanisms to provide insights into the reinforcement learning process for robotic manipulation tasks. It will develop a method to visualize which parts of the environment the agent is attending to when making a decision, allowing for improved debugging and transfer learning. The system will be evaluated on a simulated robotic manipulation environment using metrics like success rate and time to completion.",
      null,
      "[NLP] Personalized Emotional Response Generation via Contextual Storytelling\n\nThis research investigates the use of a large language model to dynamically generate emotionally resonant responses within personalized narrative contexts, aiming to improve user engagement and emotional well-being. The model will be trained on a dataset of diverse narratives and user feedback, allowing it to tailor responses to individual emotional states and preferences. Evaluation will involve subjective ratings of emotional impact and engagement metrics.",
      null
    ],
    [
      null,
      "[NLP] Personalized Dialogue Generation for Mental Health Support Chatbots\n\nThis research will develop a dialogue generation model specifically tailored for mental health chatbots, focusing on empathetic and supportive responses. The model will utilize a transformer architecture trained on a dataset of therapeutic conversations, incorporating reinforcement learning to optimize for user engagement and emotional well-being. Evaluation will be based on user surveys assessing perceived empathy, helpfulness, and overall satisfaction.",
      "[NLP] Contextualized Sentiment Analysis of Social Media Posts\n\nThis research explores the development of a novel contextualized sentiment analysis model that goes beyond simple polarity detection by incorporating discourse-level cues and emotional tone. The model will be trained on a large dataset of social media posts, utilizing a transformer architecture augmented with a discourse parsing module. Evaluation will be based on a combination of accuracy (measured by F1-score) and a novel metric, \u201cEmotional Resonance Score\u201d (ERS) which quantifies the degree to which the model\u2019s sentiment prediction aligns with the expressed emotional tone within the post.",
      "[NLP] Explainable Sentiment Analysis for Customer Service Interactions\n\nThis research investigates the development of an explainable sentiment analysis model specifically tailored for analyzing customer service interactions (e.g., chat logs, call transcripts). The model will leverage attention mechanisms to highlight the parts of the text that contribute most to the sentiment, and will provide insights into *why* a customer is expressing a particular sentiment. Data will be collected from a simulated customer service platform, and evaluation will be based on metrics like precision, recall, and F1-score, alongside human evaluation of the model\u2019s explanations.",
      "[NLP] Contrastive Learning for Bias Detection in Large Language Models\n\nThis research will develop a novel contrastive learning framework to automatically identify and quantify biases present in large language models (LLMs) across various demographic groups. We will train a model to learn positive and negative examples of text associated with different protected attributes (e.g., gender, race) and then use this learned representation to flag potentially biased outputs. Evaluation will be based on metrics like precision, recall, and F1-score across different demographic groups.",
      "[HCI] Embodied Conversational Agents for Mental Health Support",
      "[NLP] Knowledge-Aware Dialogue Generation with Episodic Memory\n\nThis research develops a dialogue generation system that incorporates episodic memory \u2013 the ability to recall and utilize past interactions \u2013 to improve coherence and engagement. The system will train a transformer model on a dataset of multi-turn dialogues, incorporating a memory module that stores and retrieves relevant past utterances and responses. Evaluation will focus on metrics like turn coherence, user engagement (measured through conversation length and user ratings), and the ability to maintain consistent character traits across multiple turns.",
      "[NLP] Explainable Dialogue Generation for Trustworthy Virtual Assistants\n\nThis research investigates methods to make dialogue generation systems more transparent and trustworthy by incorporating attention mechanisms that highlight the parts of the conversation that influenced a particular response. We will train a transformer model to generate responses, and then develop a method to visualize and interpret these attention weights, allowing users to understand *why* the model made a specific choice. Evaluation will focus on user trust and willingness to accept the assistant\u2019s recommendations.",
      "[NLP] Adaptive Persona Simulation for Mental Health Support\nThis research develops a system that utilizes a transformer model to generate personalized persona simulations for mental health support, adapting the simulated persona\u2019s emotional responses and conversational style based on user input and observed behavior. We will evaluate the system\u2019s effectiveness in reducing anxiety and promoting self-reflection using validated questionnaires and qualitative user feedback. Neighbor (6, 9) [score=0.88, last_updated=7] provides a good starting point for persona simulation, and this extension will build upon its ability to dynamically adjust emotional responses and provide supportive dialogue.",
      "[NLP] Procedural Content Generation with Emotional Resonance\nThis research explores the use of conditional generative models to create dynamic, emotionally resonant environments within virtual spaces, moving beyond static visual assets. We will develop a system that generates procedural content (e.g., floor layouts, object placement, environmental effects) conditioned on a user\u2019s emotional state inferred from facial expression analysis and physiological data (e.g., heart rate variability)."
    ],
    [
      "[NLP] Contextualized Sentiment Analysis of Social Media Posts\n\nThis research explores the development of a novel contextualized sentiment analysis model that goes beyond simple polarity detection by incorporating discourse-level cues and emotional tone. The model will be trained on a large dataset of social media posts, utilizing a transformer architecture augmented with a discourse parsing module to identify key phrases and relationships between sentences. Evaluation will be based on a held-out test set measuring accuracy, precision, recall, and F1-score, comparing against a baseline model trained on standard sentiment analysis techniques.",
      null,
      "[NLP] Explainable Sentiment Analysis for Product Reviews\n\nThis research investigates methods to provide users with transparent explanations for why a sentiment analysis model assigned a particular label to a product review. We will develop a technique that highlights the specific phrases or sentence structures that contributed most to the model\u2019s prediction, using attention mechanisms and rule-based filtering to reveal the reasoning behind the classification. The evaluation will focus on human judgments of the explanations\u2019 accuracy and helpfulness.",
      "[HCI] Personalized Emotional Response Mapping for Virtual Assistants\n\nThis research explores the design of a system that allows virtual assistants to dynamically map the emotional state of a user based on their verbal and non-verbal communication, providing a more empathetic and responsive interaction. The system will utilize a combination of speech emotion recognition (SER) and facial expression analysis, trained on a diverse dataset of user interactions. Evaluation will be based on user satisfaction ratings and a subjective measure of perceived empathy.",
      "[Cognitive Science] Investigating the Role of Bayesian Inference in Social Judgments and Bias Mitigation\n\nThis research explores how Bayesian inference \u2013 the process of updating beliefs based on new evidence \u2013 influences social judgments and biases, particularly in situations involving ambiguous or incomplete information. I will develop a computational model that simulates how individuals process social cues and make judgments, incorporating Bayesian updating and incorporating a \u2018fairness\u2019 metric to assess potential biases. The model will be trained on a dataset of social interactions with varying levels of emotional intensity and potential for misinterpretation, and will evaluate its ability to predict the likelihood of biased judgments compared to a control group.",
      "[HCI] Interactive Narrative Simulation for Trauma Recovery\n\nThis research develops an interactive narrative experience designed to help individuals process traumatic memories through a carefully constructed, branching story. The system will utilize NLP to generate dynamic responses based on user choices, incorporating elements of cognitive behavioral therapy (CBT) principles. Evaluation will be based on standardized trauma assessment tools and subjective user reports of emotional regulation and narrative engagement.",
      "[Vision]  Explainable AI (XAI) for Medical Image Diagnosis using Attention Maps\n\nThis research explores the application of attention maps derived from convolutional neural networks (CNNs) to provide explainable insights into the diagnostic reasoning of medical image analysis models. We will develop a method to visualize and interpret the attention weights assigned to different regions of an image, allowing clinicians to understand which features the model is focusing on when making a diagnosis. Evaluation will be based on human evaluation of the clarity and usefulness of the explanations, as well as quantitative metrics like accuracy and sensitivity of the model\u2019s predictions.",
      null,
      "[NLP] Interactive Narrative Simulation with Dynamic Character Alignment\n\nThis research investigates the development of a system that allows for the creation of interactive narratives where character alignment and emotional consistency are dynamically adjusted based on user feedback and contextual information. We will use a reinforcement learning approach to train a model to predict and influence character behavior, incorporating a user-defined emotional profile and a real-time analysis of narrative events. Evaluation will be based on user ratings of narrative coherence, emotional engagement, and character believability, measured using a Likert scale.",
      "[NLP] Personalized Knowledge Synthesis via Contextual Attention Networks\n\nThis research explores the use of a novel attention mechanism to enhance knowledge synthesis within large language models. We will develop a system that dynamically prioritizes and integrates relevant information from a user's past interactions and contextual knowledge base, improving the accuracy and relevance of generated summaries and explanations. We will evaluate the system using a benchmark dataset of scientific papers and user-provided questions, measuring coherence, factual correctness, and user satisfaction."
    ],
    [
      null,
      "[HCI] Context-Aware Navigation Assistance with Predictive Vibration Feedback\n\nThis research develops a mobile navigation app that dynamically adjusts route recommendations based on the user\u2019s observed gait and predicted movement patterns, utilizing subtle vibration feedback to provide a more intuitive and personalized experience. The system will integrate accelerometer and gyroscope data to forecast the user\u2019s next steps, offering proactive guidance and minimizing disorientation. Evaluation will involve user studies measuring task completion time, error rates, and subjective comfort ratings. Metrics will include frequency of successful navigation and user reported feelings of confidence.",
      "[HCI] Personalized Embodied Navigation via Predictive Vibration Mapping\n\nThis research explores the integration of haptic feedback into a mobile navigation app to provide users with more intuitive and personalized guidance. We will develop a system that uses subtle vibrations to indicate the direction of movement and potential obstacles, tailored to the user\u2019s gait and preferred navigation style. The system will leverage gait data collected through IMUs and user feedback on navigation accuracy. Evaluation will be based on subjective user ratings of navigation clarity and perceived ease of use, as well as objective metrics like time to reach destination and error rate.",
      null,
      "[NLP] Interactive Storytelling with Emotional Response Adaptation\n\nThis research will develop an interactive storytelling platform that dynamically adjusts the narrative based on the user\u2019s emotional state, utilizing a transformer model to analyze sentiment and adjust plot points, character interactions, and emotional cues in real-time. Evaluation will be based on user engagement metrics (time spent, completion rate), subjective ratings of emotional impact, and a validated emotion recognition scale.",
      "[NLP] Personalized Emotional Feedback System for Creative Writing\n\nThis research will develop a system that analyzes a writer\u2019s creative text \u2013 including prose, poetry, and scripts \u2013 to provide personalized feedback on emotional tone and engagement, using a transformer model to identify and quantify emotional states. Evaluation will be based on subjective human ratings of emotional impact and stylistic coherence, measured using a Likert scale.",
      "[NLP] Knowledge Graph Completion with Adaptive Reasoning\n\nThis research investigates the use of knowledge graph completion (KGC) techniques augmented with adaptive reasoning to improve the accuracy and robustness of question answering systems. Current KGC methods often rely on fixed reasoning rules, failing to handle complex, multi-hop queries. We propose a system that dynamically adjusts the reasoning path based on the uncertainty in the knowledge graph and the user's question, leveraging a probabilistic reasoning framework. Evaluation will be conducted on benchmark question answering datasets, measuring accuracy and efficiency.",
      null,
      null,
      "[HCI] Contextual Knowledge Graph Construction for Interactive Storytelling\n\nThis research investigates the design of a system that dynamically constructs and updates a knowledge graph representing a user's evolving narrative preferences and world knowledge during an interactive storytelling experience. We will develop a system that leverages user feedback and contextual data to automatically generate and refine a personalized knowledge graph, enhancing engagement and immersion. Data will include user choices, narrative events, and explicit feedback. Evaluation will be based on user engagement metrics (time spent, number of choices), subjective ratings of narrative coherence and interest, and a measure of knowledge graph completeness."
    ],
    [
      "[Cognitive Psychology] Personalized Route Preference Shaping through Attention Dynamics\n\nThis research explores how individual differences in visual attention influence route preference and adherence, proposing a system that dynamically adjusts route recommendations based on predicted attentional shifts. Data will include eye-tracking, route tracking, and user-reported attention levels. Evaluation will be based on subjective user ratings of route adherence and perceived cognitive effort.",
      "[HCI] Dynamic Route Adaptation via Predictive Motion Analysis\n\nThis research investigates a system that uses predictive motion analysis to dynamically adjust route recommendations in real-time, based on the user\u2019s observed gait and anticipated movement patterns. It leverages a combination of accelerometer and gyroscope data to forecast the user\u2019s next steps, offering a more personalized and proactive navigation experience. We will evaluate the system\u2019s effectiveness through a series of controlled trials with diverse user groups, measuring metrics such as route completion time, user satisfaction, and adherence to preferred navigation styles.",
      "[NLP] Adaptive Emotional Response in Crisis Communication via Large Language Model\n\nThis research develops a large language model (LLM) fine-tuned on emergency response narratives to generate emotionally appropriate and contextually relevant responses to users expressing distress during crisis situations. Data will include transcripts of emergency calls and user feedback. Evaluation will be based on user ratings of the LLM\u2019s empathy and helpfulness, measured through a Likert scale.",
      "[NLP] Visual-Textual Sentiment Alignment for Crisis Prediction\n\nThis research will develop a system that aligns visual and textual sentiment expressed in social media posts with a specific crisis event, using a transformer model to identify correlations between image and text cues. The system will leverage a dataset of social media posts and corresponding images, and evaluate performance using a custom metric combining precision and recall on crisis prediction tasks.",
      "[NLP] Dynamic Crisis Prediction via Multi-Modal Sentiment Fusion\nThis research will develop a system that predicts potential crises by fusing sentiment analysis from social media posts with visual cues (e.g., image analysis) and textual context, leveraging a transformer model to dynamically adjust the weighting of each modality. Evaluation will be based on precision and recall for identifying emerging crisis indicators, as well as a user-defined metric of time to detection.",
      null,
      "[NLP] Contrastive Learning for Explainable AI\n\nThis research explores using contrastive learning to improve the explainability of deep learning models by generating synthetic data that highlights the model's decision-making process. It leverages a pre-trained language model to create pairs of inputs and their corresponding explanations, allowing for a more granular understanding of how the model arrives at its predictions. Data: A dataset of image classification tasks with corresponding human-generated explanations. Evaluation:  Metrics like BLEU score and human evaluation of explanation quality.",
      "[HCI] Personalized Feedback Loop for Interactive Storytelling\n\nThis research investigates the design of a personalized feedback loop within an interactive storytelling platform, utilizing reinforcement learning to adapt narrative choices based on user emotional responses. It will focus on creating a system that dynamically adjusts the story's pacing, character interactions, and plot elements based on real-time sentiment analysis of user facial expressions and voice tone, aiming to increase engagement and emotional investment. Data will include user facial expression data (via webcam) and voice tone analysis, and metrics will include average session length, user satisfaction scores, and frequency of emotional engagement.",
      null,
      "[Safety] Algorithmic Bias Detection in Autonomous Vehicle Perception Systems\n\nThis research will develop a novel framework for detecting and quantifying algorithmic bias in pedestrian detection models used by autonomous vehicles. The framework will leverage a combination of adversarial training and explainable AI (XAI) techniques to identify disparities in detection rates across demographic groups (e.g., based on age, race, and gender). We will evaluate the framework using a publicly available dataset of pedestrian images and metrics such as precision, recall, and F1-score, focusing on identifying patterns indicative of biased model behavior."
    ]
  ]
}