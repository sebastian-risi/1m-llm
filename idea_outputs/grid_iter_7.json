{
  "scores": [
    [
      0.0,
      0.0,
      0.0,
      0.7432681677754523,
      0.7250000000000001,
      0.7409545604758758,
      0.7852666884619015,
      0.0,
      0.0,
      0.8875
    ],
    [
      0.6375,
      0.6977211538461539,
      0.8319772115384615,
      0.8389057524001601,
      0.8101075824692797,
      0.7250000000000001,
      0.0,
      0.775,
      0.0,
      0.0
    ],
    [
      0.7857857142857143,
      0.7987019431643625,
      0.0,
      0.0,
      0.0,
      0.0,
      0.8125,
      0.0,
      0.8378514835164834,
      0.6807527472527473
    ],
    [
      0.9,
      0.0,
      0.0,
      0.8375,
      0.0,
      0.7331391509433962,
      0.0,
      0.875,
      0.0,
      0.0
    ],
    [
      0.6567272727272727,
      0.0,
      0.661860074650009,
      0.791270622895623,
      0.8167541208791209,
      0.8375,
      0.6897579787234043,
      0.750279822378879,
      0.4,
      0.0
    ],
    [
      0.0,
      0.65,
      0.0,
      0.8077292917956657,
      0.7649842735603188,
      0.8456118421052632,
      0.0,
      0.0,
      0.8773498118115055,
      0.0
    ],
    [
      0.0,
      0.0,
      0.7875000000000001,
      0.795375,
      0.0,
      0.7218471981424148,
      0.7792779942751901,
      0.0,
      0.8797180232558139,
      0.7625
    ],
    [
      0.8125,
      0.0,
      0.0,
      0.0,
      0.675,
      0.7579507236622053,
      0.7594320805802385,
      0.0,
      0.8123389486741801,
      0.8381805555555555
    ],
    [
      0.0,
      0.8375,
      0.661784090909091,
      0.0,
      0.7578421795647967,
      0.0,
      0.8489950300256605,
      0.0,
      0.0,
      0.0
    ],
    [
      0.6917217435032484,
      0.7382663043478261,
      0.0,
      0.7192916666666667,
      0.7308784388544474,
      0.0,
      0.708164020916778,
      0.0,
      0.0,
      0.8625
    ]
  ],
  "last_updated": [
    [
      -1,
      -1,
      -1,
      6,
      1,
      5,
      7,
      -1,
      -1,
      3
    ],
    [
      1,
      1,
      3,
      5,
      6,
      2,
      -1,
      2,
      -1,
      -1
    ],
    [
      2,
      6,
      -1,
      -1,
      -1,
      -1,
      7,
      -1,
      7,
      7
    ],
    [
      2,
      -1,
      -1,
      4,
      -1,
      4,
      -1,
      6,
      -1,
      -1
    ],
    [
      4,
      -1,
      7,
      5,
      4,
      2,
      3,
      6,
      2,
      -1
    ],
    [
      -1,
      7,
      -1,
      6,
      7,
      5,
      -1,
      -1,
      7,
      -1
    ],
    [
      -1,
      -1,
      3,
      3,
      -1,
      5,
      6,
      -1,
      6,
      4
    ],
    [
      1,
      -1,
      -1,
      -1,
      5,
      6,
      4,
      -1,
      7,
      4
    ],
    [
      -1,
      2,
      4,
      -1,
      7,
      -1,
      6,
      -1,
      -1,
      -1
    ],
    [
      4,
      3,
      -1,
      2,
      5,
      -1,
      3,
      -1,
      -1,
      1
    ]
  ],
  "ideas": [
    [
      null,
      null,
      null,
      "[Safety] Bias Detection in Personalized Recommendation Systems\n\nThis research will develop a novel method for detecting and quantifying bias in personalized recommendation systems by analyzing user behavior across multiple platforms and identifying patterns indicative of unfairness. The system will use a combination of differential privacy techniques and adversarial training to identify and mitigate potential biases related to demographic factors and user preferences. Data will include user interaction logs, explicit feedback, and simulated user profiles. Evaluation will involve measuring fairness metrics such as equal opportunity and demographic parity across different user groups.",
      "[Evaluation] Dynamic Attention Network for Visual Scene Understanding\n\nThis research explores a novel dynamic attention mechanism for visual scene understanding, aiming to improve performance on complex scenes with occlusions and varying object scales. The idea involves extending the standard self-attention mechanism to incorporate a \"contextual memory\" layer that dynamically adjusts the attention weights based on recent visual input. We will evaluate the network on a dataset of human-annotated scenes with varying levels of occlusion and object scale using metrics like Mean Intersection over Union (mIoU) and a custom metric measuring the accuracy of object segmentation.",
      "[NLP] Text-to-Image Style Transfer for Enhanced Narrative Generation\n\nThis project explores the use of a novel text-to-image style transfer technique to dynamically adjust the visual style of generated narratives, enhancing their emotional impact and reader engagement. The system will utilize a diffusion model fine-tuned on a dataset of emotionally-labeled stories, and will evaluate the generated narratives based on human ratings of emotional valence and narrative coherence.",
      "[NLP] Dynamic Narrative Adaptation via Attention-Based Style Control\nThis project aims to develop a novel approach to interactive storytelling by dynamically adjusting the narrative style (tone, pacing, descriptive language) based on real-time user sentiment analysis of textual feedback. The system will utilize a transformer model fine-tuned on user-generated stories, incorporating attention mechanisms to prioritize emotionally-charged feedback. Evaluation will be based on average user ratings and qualitative analysis of user responses.",
      null,
      null,
      "[HCI] Personalized Embodied Feedback for Navigation\n\nThis research explores the use of haptic feedback to provide personalized navigational cues for users with visual impairments. We will develop a system that uses a wearable device to deliver subtle vibrations and tactile patterns correlated to the user\u2019s intended movement, allowing them to \u2018feel\u2019 their way through a space. Evaluation will focus on subjective user ratings of ease of navigation, perceived confidence, and reduction in anxiety, using a controlled lab setting with participants with low visual acuity."
    ],
    [
      "[Cognitive Science] Exploring the Role of Predictive Coding in Social Memory Consolidation\n\nThis research investigates how predictive coding mechanisms influence the consolidation of social memories \u2013 memories of interactions with others. I will build a simulated environment where participants are presented with a series of social interactions, and then receive a \"prediction\" of the likely outcome of the interaction.  The goal is to determine if participants exhibit increased memory consolidation when they receive a more accurate prediction, compared to a less accurate one. Data will include EEG recordings to measure neural activity associated with prediction and consolidation, and a subjective rating of memory recall accuracy. Metrics will include accuracy of recall and subjective ratings of emotional intensity.",
      "[Safety] Bias Detection in Personalized Recommendation Systems\n\nThis research will develop a novel method for detecting subtle biases embedded within personalized recommendation systems by analyzing the diversity of items presented to users. I will build a system that identifies when a user consistently receives recommendations that are highly similar to those they\u2019ve previously engaged with, even if those recommendations are not explicitly biased. Data will include user interaction history, item metadata, and a measure of similarity between items. Evaluation will involve comparing the system\u2019s detection rate to human annotators and assessing the impact on user satisfaction.",
      "[Evaluation] Dynamic Attention Weighting for Explainable AI\n\nThis research will develop a dynamic attention weighting mechanism for large language models (LLMs) that adjusts the importance of different parts of the input sequence based on the user's current query and context. I will build a system that iteratively refines attention weights using a reinforcement learning approach, optimizing for both accuracy and interpretability. Data will include a diverse set of user queries and corresponding model outputs, and evaluation will be based on human evaluation of model faithfulness and helpfulness.",
      "[NLP] Contextualized Sentiment Analysis with Visual Grounding\n\nThis research will develop a system that analyzes sentiment in text by combining contextual understanding with visual cues from an image. The system will use a transformer model to identify sentiment, but will also incorporate visual features (e.g., facial expressions, object recognition) to provide a richer understanding of the sentiment expressed. I will evaluate the system using a held-out dataset of text and images, measuring accuracy and F1-score on sentiment classification and visual similarity.",
      "[Vision]  Interactive Scene Graph Generation for Robotic Manipulation\n\nThis research explores a method for generating interactive scene graphs \u2013 representations of the environment that robots can use to plan and execute manipulation tasks \u2013 leveraging visual information and object properties. It will utilize a graph neural network to learn a representation of the scene, incorporating object attributes and spatial relationships, and then generate a sequence of actions that a robot can execute. Evaluation will be based on the success rate of successful manipulation tasks, measured by the number of successful grasp events and the time taken to complete the task.",
      "[ML] Personalized Synthetic Data Generation for Climate Modeling\n\nThis project aims to develop a system that generates synthetic climate data tailored to specific model parameters and scenarios, significantly augmenting existing datasets for improved climate modeling accuracy. The system will utilize a Generative Adversarial Network (GAN) trained on a large collection of historical climate data, with the generator producing synthetic data that closely mimics the statistical properties of the real data. Evaluation will be based on comparing the synthetic data to real data using metrics like statistical similarity (e.g., Kolmogorov-Smirnov test) and model performance on a climate model validation set.",
      null,
      "[HCI] Personalized Embodied Feedback for Navigation Assistance\n\nThis research explores the integration of haptic feedback into a mobile navigation app to provide personalized, contextual guidance. Users will wear a small, lightweight device that delivers subtle vibrations and tactile cues based on their current location and planned route. The system will learn user preferences through a short onboarding phase and adapt feedback based on observed behavior (e.g., avoiding obstacles, quickly finding routes). Evaluation will involve measuring task completion time, user satisfaction (using a Likert scale), and the frequency of successful navigation.",
      null,
      null
    ],
    [
      "[NLP] Personalized Dialogue Style Analysis using Transformer Networks\n\nThis research explores the impact of dialogue style on user engagement and satisfaction in virtual assistants. I will develop a transformer-based model that analyzes user responses to virtual assistants, identifying distinct stylistic patterns (e.g., formal, informal, humorous) and correlating these patterns with user sentiment and task completion rates. Data will include a dataset of user-assistant interactions, labeled with stylistic features and user feedback. Evaluation will be based on user satisfaction scores and task completion time.",
      "[NLP] Contextual Sentiment Shift Detection in Conversational AI\n\nThis research will develop a model that analyzes the sentiment expressed within a conversation, identifying shifts in sentiment that indicate a user is becoming frustrated or dissatisfied with the AI's responses. I will build a model leveraging transformer networks to detect subtle changes in sentiment expressed through word choice, emoji usage, and conversational tone, and will evaluate performance using a held-out dataset of user-AI conversations labeled with sentiment scores.",
      null,
      null,
      null,
      null,
      "[Cognitive Science] Investigating the Impact of Episodic Memory Retrieval on Social Bias Amplification\n\nThis research explores how readily available episodic memories of specific social interactions can inadvertently amplify existing biases towards particular individuals, potentially leading to inaccurate judgments of trustworthiness or competence. Participants will be presented with a series of short, ambiguous social scenarios, and their responses will be analyzed to determine if retrieval of related memories significantly alters their subsequent judgments.  The study will utilize fMRI to examine neural activity associated with bias detection and consolidation.",
      null,
      "[Visualization] Generative Adversarial Networks (GANs) for Realistic Texture Synthesis from Limited Data\n\nThis research investigates the application of Generative Adversarial Networks (GANs) to synthesize realistic textures from small, sparse datasets. The approach will involve training a GAN to generate textures conditioned on a limited set of visual examples, allowing for the creation of novel materials and surfaces. Evaluation will focus on perceptual quality metrics (e.g., LPIPS) and the ability to generate textures that closely match the characteristics of provided reference images.",
      "[Vision] Interactive Narrative Generation with Visual Storytelling\n\nThis research explores the use of a conditional generative model to dynamically generate visual story elements (e.g., character poses, environment details, object appearances) based on a user's textual input, creating an interactive narrative experience. I will leverage a transformer-based model to map textual descriptions to visual representations, incorporating a reinforcement learning component to optimize for user engagement and coherence. Data will include a dataset of short narrative scenes and corresponding visual representations. Evaluation will be based on user ratings of narrative coherence, visual appeal, and engagement metrics derived from user interaction."
    ],
    [
      "[NLP] Discourse-Aware Sentiment Prediction with Knowledge Graph Integration\nThis research investigates the integration of knowledge graphs into sentiment prediction models, aiming to improve accuracy by leveraging contextual knowledge and relationships between entities. The model will be trained on a dataset of social media posts, incorporating external knowledge from a curated knowledge graph (e.g., Wikidata) to enhance sentiment understanding. Evaluation will be based on F1-score and a novel metric assessing the coherence and consistency of the model\u2019s sentiment predictions with the knowledge graph.",
      null,
      null,
      "[HCI] Personalized Embodied Feedback for Navigation Assistance\n\nThis research explores the integration of haptic feedback into a mobile navigation app to provide users with more intuitive and personalized guidance. We will develop a system that uses subtle vibrations to indicate the direction of movement and potential obstacles, tailored to the user\u2019s gait and preferred navigation style. The system will be evaluated through user studies measuring task completion time, error rates, and subjective ratings of comfort and ease of use. Metrics will include frequency of successful navigation and user reported feelings of confidence.",
      null,
      "[Safety] Bias Detection in Personalized Recommendation Systems\n\nThis research explores the potential for subtle biases embedded within personalized recommendation systems to disproportionately affect marginalized groups. We will develop a novel method for analyzing user behavior across multiple platforms (e.g., web, mobile) to identify and quantify these biases, focusing on factors like demographic representation and interaction patterns. Data will include user profiles, interaction history, and potentially, anonymized behavioral data. Evaluation will involve comparing the system\u2019s recommendations to established fairness metrics and conducting qualitative analysis of user feedback to assess perceived bias.",
      null,
      "[Vision] Visual Grounding for Dialogue: Exploring Contextualized Visual Anchors for Conversational Agents. This research will develop a system that allows conversational agents to reliably ground their responses in visual context \u2013 specifically, using a small set of pre-defined visual anchors (e.g., a specific object, a room scene) to improve coherence and understanding of user intent. We will evaluate the system using a user study where participants are asked to complete tasks requiring visual reasoning, measuring accuracy and perceived coherence.",
      null,
      null
    ],
    [
      "[NLP] Explainable Sentiment Analysis with Attention-Based Graph Embedding\nThis research explores using attention mechanisms to enhance explainability in sentiment analysis models, particularly by incorporating graph embeddings derived from knowledge graphs. The model will be trained on a dataset of social media posts, and explainability will be evaluated using methods like SHAP and LIME, focusing on identifying the most influential entities driving sentiment predictions.",
      null,
      "[Cognitive Science] Investigating the Impact of Implicit Social Evaluation on Episodic Memory Retrieval\n\nThis research explores how implicit social evaluation \u2013 the unconscious assessment of a person\u2019s behavior based on observed actions \u2013 influences the retrieval of episodic memories. We will use fMRI to examine neural activity during a simulated social interaction, focusing on regions associated with reward processing and social cognition. The goal is to determine if repeated implicit evaluations of a person\u2019s actions strengthen the encoding of relevant episodic memories, leading to improved recall. Data will include behavioral measures of social evaluation (e.g., facial expressions, verbal comments) and fMRI data capturing neural responses to simulated social interactions.",
      "[NLP] Sentiment-Aware Dialogue Generation for Crisis Support\n\nThis research aims to develop a dialogue agent that dynamically adjusts its response style based on the user\u2019s expressed emotional state, improving the effectiveness of crisis support conversations. We will utilize a transformer model fine-tuned on a dataset of crisis conversations and incorporate a sentiment analysis module to monitor the user\u2019s emotional cues. Evaluation will be based on user satisfaction scores and a measure of crisis resolution success.",
      "[NLP] Contextualized Dialogue State Tracking with Attention\n\nThis research explores the use of attention mechanisms to improve the contextual understanding of dialogue states within a large language model. We will develop a system that dynamically weights different parts of the dialogue history based on their relevance to the current turn, enhancing the model\u2019s ability to track user goals and intentions across longer conversations. Data will be collected through a series of simulated dialogues, and evaluation will be based on task completion rate and user satisfaction scores.",
      "[Vision] Visual Grounding for Dialogue Response Generation\n\nThis research investigates the integration of visual cues (e.g., facial expressions, body posture) with textual dialogue to improve the coherence and naturalness of response generation. We will develop a model that learns to associate visual features with specific dialogue intents, enabling the system to better understand the user\u2019s emotional state and intentions, leading to more engaging and relevant responses. Evaluation will be conducted using a dataset of multi-modal dialogues, focusing on metrics like user engagement and task completion rate.",
      "[NLP] Contextualized Dialogue State Tracking with Attention\n\nThis research explores a novel approach to dialogue state tracking that leverages attention mechanisms to dynamically weight the importance of different contextual cues during response generation. It builds upon the existing work of incorporating visual cues into dialogue understanding, but instead of relying solely on facial expressions, it focuses on analyzing body posture and gestures to refine the model\u2019s understanding of the user\u2019s emotional state and intent. We will evaluate the model\u2019s performance on a benchmark dataset of multi-turn conversations, measuring metrics such as coherence, relevance, and user satisfaction.",
      "[NLP] Personalized Knowledge Graph Construction for Scientific Discovery\n\nThis research will develop a system that automatically constructs personalized knowledge graphs for researchers based on their current research interests and publications. The system will leverage a combination of text mining, citation analysis, and knowledge graph embedding techniques to identify relevant entities and relationships, and then iteratively refine these graphs to reflect the researcher\u2019s evolving understanding of the field. We will evaluate the quality of the generated knowledge graphs using metrics such as coverage, coherence, and novelty, and assess their impact on research productivity through user surveys.",
      "[NLP] Contextual Sentiment Analysis of Social Media Posts for Proactive Crisis Detection",
      null
    ],
    [
      null,
      "[Safety] Algorithmic Bias Detection in Autonomous Vehicle Perception Systems\n\nThis research will develop a novel framework for detecting and quantifying algorithmic bias in pedestrian detection models used by autonomous vehicles. The framework will leverage a combination of adversarial training and explainable AI (XAI) techniques to identify subtle biases that might lead to disproportionate risk assessments for certain demographic groups. Data will include a diverse set of pedestrian datasets augmented with simulated adversarial examples generated using a modified adversarial attack algorithm. Evaluation will be based on metrics like false positive rate and disparate impact analysis, focusing on the fairness of risk assessment across different demographic groups.",
      null,
      "[NLP] Visual-Textual Sentiment Alignment for Enhanced Dialogue Quality\n\nThis research explores how visual cues (e.g., facial expressions in videos, objects in images) can be integrated with textual dialogue to improve the coherence and emotional resonance of conversations. We will develop a model that analyzes both the text and visual data to predict the user's emotional state and adjust the dialogue accordingly, leveraging a transformer model trained on paired visual and textual data. We will evaluate the model\u2019s performance using metrics like coherence score and user ratings of emotional engagement.",
      "[NLP] Knowledge Graph Completion with Adversarial Training for Enhanced Reasoning\n\nThis research explores the use of adversarial training to improve the accuracy and robustness of knowledge graph completion. We will train a model to predict missing relationships between entities in a knowledge graph, incorporating an adversarial component that encourages the model to generate plausible but incorrect completions. We will evaluate the model on benchmark knowledge graphs and human-annotated datasets using metrics like accuracy and consistency.",
      "[NLP] Contextualized Sentiment Analysis for Scientific Report Generation\n\nThis research aims to develop a system that automatically generates concise and informative summaries of scientific reports, incorporating contextual sentiment analysis to ensure the report accurately reflects the author's intended message and audience. We will use a transformer-based model fine-tuned on a dataset of scientific reports and their associated sentiment scores. Evaluation will be based on human assessment of report clarity, accuracy, and persuasiveness, as well as automated metrics like ROUGE and BLEU for summarization quality.",
      null,
      null,
      "[NLP] Interactive Narrative Simulation for Emotional Regulation\n\nThis research explores the use of a reinforcement learning agent to simulate emotionally challenging narrative scenarios, designed to improve emotional regulation skills in users. The agent will respond to user choices within a dynamically generated story, providing feedback on emotional states and guiding the user towards more adaptive responses. We will evaluate the agent\u2019s effectiveness using a combination of physiological data (heart rate variability) and self-reported emotion ratings, focusing on improvements in anxiety and stress reduction.",
      null
    ],
    [
      null,
      null,
      "[NLP] Contextualized Sentiment Analysis of Social Media Posts\n\nThis research explores the development of a novel contextualized sentiment analysis model that goes beyond simple polarity detection by incorporating discourse-level cues and emotional tone. The model will be trained on a large dataset of social media posts, utilizing a transformer architecture augmented with a discourse parsing module. Evaluation will be based on a combination of accuracy (measured by F1-score) and a novel metric, \u201cEmotional Resonance Score\u201d (ERS) which quantifies the degree to which the model\u2019s sentiment prediction aligns with the expressed emotional tone within the post.",
      "[NLP] Explainable Sentiment Analysis for Customer Service Interactions\n\nThis research investigates the development of an explainable sentiment analysis model specifically tailored for analyzing customer service interactions (e.g., chat logs, call transcripts). The model will leverage attention mechanisms to highlight the parts of the text that contribute most to the sentiment, and will provide insights into *why* a customer is expressing a particular sentiment. Data will be collected from a simulated customer service platform, and evaluation will be based on metrics like precision, recall, and F1-score, alongside human evaluation of the model\u2019s explanations.",
      null,
      "[HCI] Personalized Feedback Loop for Creative Writing Assistance\n\nThis research explores a system that provides personalized feedback to creative writers, leveraging a combination of NLP and reinforcement learning. The system will analyze a writer's draft and generate suggestions for stylistic improvements, plot development, and character consistency, all tailored to their individual creative process. Data will include the writer\u2019s previous work, feedback provided by other users, and a curated dataset of successful creative writing examples. Evaluation will be based on user ratings of the suggestions\u2019 helpfulness and impact on the writing process, as well as automated metrics measuring stylistic coherence and narrative structure.",
      "[NLP] Knowledge-Aware Dialogue Generation with Episodic Memory\n\nThis research develops a dialogue generation system that incorporates episodic memory \u2013 the ability to recall and utilize past interactions \u2013 to improve coherence and engagement. The system will train a transformer model on a dataset of multi-turn dialogues, incorporating a memory module that stores and retrieves relevant past utterances and responses. Evaluation will focus on metrics like turn coherence, user engagement (measured through conversation length and user ratings), and the ability to maintain consistent character traits across multiple turns.",
      null,
      "[NLP] Personalized Dialogue Generation with Contextual Memory\n\nThis research explores the use of a transformer-based model to generate dialogue for virtual assistants, incorporating a memory network to retain and utilize past conversation history. We will evaluate the model\u2019s ability to maintain coherence and relevance across extended conversations, focusing on metrics like user satisfaction and task completion rate.  Neighbor (6, 9) [score=0.76, last_updated=4] provides a strong foundation for dialogue generation, and this extension will build upon its ability to maintain context and personalize responses.",
      "[NLP] Interactive Storytelling with Dynamic Character Reactions\nThis research investigates the use of reinforcement learning to dynamically adjust character reactions and dialogue based on player choices within interactive stories, enhancing immersion and narrative engagement. We will develop a system that learns to respond to player actions in real-time, generating believable and evolving character dialogue and behavior, utilizing a combination of natural language understanding and reinforcement learning."
    ],
    [
      "[NLP] Contextualized Sentiment Analysis of Social Media Posts\n\nThis research explores the development of a novel contextualized sentiment analysis model that goes beyond simple polarity detection by incorporating discourse-level cues and emotional tone. The model will be trained on a large dataset of social media posts, utilizing a transformer architecture augmented with a discourse parsing module to identify key phrases and relationships between sentences. Evaluation will be based on a held-out test set measuring accuracy, precision, recall, and F1-score, comparing against a baseline model trained on standard sentiment analysis techniques.",
      null,
      null,
      null,
      "[Cognitive Science] Exploring the Role of Predictive Coding in Social Memory Consolidation\n\nThis research investigates whether predictive coding mechanisms within the hippocampus play a crucial role in consolidating social memories, specifically those involving emotional context and perceived threat. I will build a computational model simulating the hippocampus\u2019s activity during the replay of social interactions, using a combination of fMRI data and behavioral measures of emotional response. The model will focus on predicting the next state of the social interaction based on past experiences, and will evaluate its ability to improve the accuracy of recall of emotionally charged social events compared to a control group with no predictive coding simulation.",
      "[HCI] Interactive Narrative Simulation for Trauma Recovery\n\nThis research develops an interactive narrative experience designed to help individuals process traumatic memories through a carefully constructed, branching story. The system will utilize NLP to generate dynamic responses based on user choices, incorporating elements of cognitive behavioral therapy (CBT) principles. Evaluation will be based on standardized trauma assessment tools and subjective user reports of emotional regulation and narrative engagement.",
      "[Vision]  Generative Adversarial Networks (GANs) for Synthetic Image Data Augmentation for Medical Image Segmentation\n\nThis research proposes a novel GAN architecture specifically designed to generate synthetic medical images with high fidelity, addressing the scarcity of labeled medical data. The GAN will be trained on a dataset of real medical images and will generate variations of existing images, including simulated lesions, anatomical variations, and different imaging modalities.  Evaluation will be based on metrics like Intersection over Union (IoU) and Dice coefficient, comparing the performance of the synthetic data on a downstream segmentation task (e.g., tumor segmentation).",
      null,
      "[NLP] Interactive Narrative Simulation with Dynamic Character Alignment\n\nThis research investigates the development of a system that allows for the creation of interactive narratives where character alignment and emotional consistency are dynamically adjusted based on user feedback and contextual information. We will use a reinforcement learning approach to train a model to predict and influence character behavior, incorporating a user-defined emotional profile and a real-time analysis of narrative events. Evaluation will be based on user ratings of narrative coherence, emotional engagement, and character believability, measured using a Likert scale.",
      "[NLP] Personalized Knowledge Synthesis via Contextual Attention Networks\n\nThis research explores the use of a novel attention mechanism to enhance knowledge synthesis within large language models. We will develop a system that dynamically prioritizes and integrates relevant information from a user's past interactions and contextual knowledge base, improving the accuracy and relevance of generated summaries and explanations. We will evaluate the system using a benchmark dataset of scientific papers and user-provided questions, measuring coherence, factual correctness, and user satisfaction."
    ],
    [
      null,
      "[HCI] Personalized Embodied Feedback for Navigation Assistance\n\nThis research explores the integration of haptic feedback into a mobile navigation app to provide users with more intuitive and personalized guidance. We will develop a system that uses subtle vibrations to indicate the direction of movement and potential obstacles, tailored to the user\u2019s gait and preferred navigation style. The system will be evaluated through user studies measuring task completion time, error rates, and subjective ratings of comfort and ease of use. Metrics will include frequency of successful navigation and user reported feelings of confidence.",
      "[HCI] Dynamic Embodied Navigation via Predictive Vibration Mapping\n\nThis research investigates the use of predictive vibration mapping to enhance navigation assistance in mobile apps. We will develop a system that analyzes the user\u2019s gait and predicts potential navigational challenges based on subtle vibration patterns, proactively adjusting the app\u2019s guidance to minimize disorientation. Data will include gait data collected through inertial measurement units (IMUs) and user feedback on navigation accuracy. Evaluation will be based on subjective user ratings of navigation clarity and perceived ease of use, as well as objective metrics like time to reach destination and error rate.",
      null,
      "[NLP] Interactive Storytelling with Emotional Response Adaptation\n\nThis research will develop an interactive storytelling platform that dynamically adjusts the narrative based on the user\u2019s emotional state, utilizing a transformer model to analyze sentiment and adjust plot points, character interactions, and emotional cues in real-time. Evaluation will be based on user engagement metrics (time spent, completion rate), subjective ratings of emotional impact, and a validated emotion recognition scale.",
      null,
      "[NLP] Knowledge Graph Completion with Adaptive Reasoning\n\nThis research investigates the use of knowledge graph completion (KGC) techniques augmented with adaptive reasoning to improve the accuracy and robustness of question answering systems. Current KGC methods often rely on fixed reasoning rules, failing to handle complex, multi-hop queries. We propose a system that dynamically adjusts the reasoning path based on the uncertainty in the knowledge graph and the user's question, leveraging a probabilistic reasoning framework. Evaluation will be conducted on benchmark question answering datasets, measuring accuracy and efficiency.",
      null,
      null,
      null
    ],
    [
      "[Cognitive Psychology] Adaptive Route Guidance via Predictive Attention\n\nThis research investigates how visual attention shifts during route navigation, and how this shifts can be leveraged to improve route adherence and reduce cognitive load. It will develop a system that analyzes visual attention patterns (using eye-tracking) and dynamically adjusts route recommendations to capitalize on periods of heightened attention, promoting more consistent route following. Data will include eye-tracking data, route tracking data, and user-reported attention levels. Evaluation will be based on subjective user ratings of route adherence and perceived cognitive effort.",
      "[HCI] Dynamic Route Adaptation via Predictive Motion Analysis\n\nThis research investigates a system that uses predictive motion analysis to dynamically adjust route recommendations in real-time, based on the user\u2019s observed gait and anticipated movement patterns. It leverages a combination of accelerometer and gyroscope data to forecast the user\u2019s next steps, offering a more personalized and proactive navigation experience. We will evaluate the system\u2019s effectiveness through a series of controlled trials with diverse user groups, measuring metrics such as route completion time, user satisfaction, and adherence to preferred navigation styles.",
      null,
      "[NLP] Visual-Textual Sentiment Alignment for Crisis Prediction\n\nThis research will develop a system that aligns visual and textual sentiment expressed in social media posts with a specific crisis event, using a transformer model to identify correlations between image and text cues. The system will leverage a dataset of social media posts and corresponding images, and evaluate performance using a custom metric combining precision and recall on crisis prediction tasks.",
      "[NLP] Dynamic Crisis Prediction via Multi-Modal Sentiment Fusion\nThis research will develop a system that predicts potential crises by fusing sentiment analysis from social media posts with visual cues (e.g., image analysis) and textual context, leveraging a transformer model to dynamically adjust the weighting of each modality. Evaluation will be based on precision and recall for identifying emerging crisis indicators, as well as a user-defined metric of time to detection.",
      null,
      "[NLP] Reinforcement Learning for Dialogue Act Selection\n\nThis research explores using reinforcement learning to dynamically select dialogue acts from a set of possible responses, optimizing for user engagement and task completion. It builds upon the existing work of selecting responses based on keywords and sentiment analysis, but instead of relying on pre-defined rules, it trains an agent to learn optimal action sequences through trial and error, evaluating performance based on user feedback and task success rates. Data: A dataset of multi-turn conversations with user feedback and task completion labels. Evaluation: Mean Reciprocal Rank (MRR) and user satisfaction scores.",
      null,
      null,
      "[Safety] Algorithmic Bias Detection in Autonomous Vehicle Perception Systems\n\nThis research will develop a novel framework for detecting and quantifying algorithmic bias in pedestrian detection models used by autonomous vehicles. The framework will leverage a combination of adversarial training and explainable AI (XAI) techniques to identify disparities in detection rates across demographic groups (e.g., based on age, race, and gender). We will evaluate the framework using a publicly available dataset of pedestrian images and metrics such as precision, recall, and F1-score, focusing on identifying patterns indicative of biased model behavior."
    ]
  ]
}