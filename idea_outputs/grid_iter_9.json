{
  "scores": [
    [
      0.0,
      0.0,
      0.0,
      0.7432681677754523,
      0.7250000000000001,
      0.7409545604758758,
      0.6949095456047587,
      0.0,
      0.768375,
      0.8875
    ],
    [
      0.5743428195488722,
      0.6977211538461539,
      0.807763255213347,
      0.8389057524001601,
      0.8101075824692797,
      0.8834213041062401,
      0.0,
      0.775,
      0.0,
      0.6863060992796743
    ],
    [
      0.7857857142857143,
      0.7987019431643625,
      0.0,
      0.0,
      0.0,
      0.0,
      0.8125,
      0.0,
      0.8378514835164834,
      0.6807527472527473
    ],
    [
      0.7912140921136576,
      0.0,
      0.0,
      0.8375,
      0.0,
      0.7372301401869159,
      0.684964110314398,
      0.875,
      0.0,
      0.7981233169462116
    ],
    [
      0.6567272727272727,
      0.8176379726529688,
      0.5413268222044059,
      0.791270622895623,
      0.8167541208791209,
      0.8375,
      0.6897579787234043,
      0.750279822378879,
      0.4,
      0.0
    ],
    [
      0.0,
      0.65,
      0.0,
      0.8077292917956657,
      0.7649842735603188,
      0.8456118421052632,
      0.0,
      0.0,
      0.8773498118115055,
      0.0
    ],
    [
      0.0,
      0.0,
      0.7875000000000001,
      0.795375,
      0.8405406108533753,
      0.40845611842105267,
      0.7792779942751901,
      0.0,
      0.8797180232558139,
      0.7625
    ],
    [
      0.8125,
      0.0,
      0.0,
      0.7916812409963986,
      0.675,
      0.7579507236622053,
      0.7594320805802385,
      0.0,
      0.8123389486741801,
      0.8381805555555555
    ],
    [
      0.0,
      0.6174185482109423,
      0.6898843602535745,
      0.0,
      0.7578421795647967,
      0.6877350359014044,
      0.8489950300256605,
      0.0,
      0.0,
      0.0
    ],
    [
      0.6917217435032484,
      0.7382663043478261,
      0.7837105018713171,
      0.7192916666666667,
      0.7308784388544474,
      0.0,
      0.8693232836335899,
      0.0,
      0.0,
      0.8625
    ]
  ],
  "last_updated": [
    [
      -1,
      -1,
      -1,
      6,
      1,
      5,
      8,
      -1,
      8,
      3
    ],
    [
      9,
      1,
      8,
      5,
      6,
      8,
      -1,
      2,
      -1,
      9
    ],
    [
      2,
      6,
      -1,
      -1,
      -1,
      -1,
      7,
      -1,
      7,
      7
    ],
    [
      9,
      -1,
      -1,
      4,
      -1,
      8,
      9,
      6,
      -1,
      8
    ],
    [
      4,
      8,
      8,
      5,
      4,
      2,
      3,
      6,
      2,
      -1
    ],
    [
      -1,
      7,
      -1,
      6,
      7,
      5,
      -1,
      -1,
      7,
      -1
    ],
    [
      -1,
      -1,
      3,
      3,
      9,
      8,
      6,
      -1,
      6,
      4
    ],
    [
      1,
      -1,
      -1,
      9,
      5,
      6,
      4,
      -1,
      7,
      4
    ],
    [
      -1,
      8,
      9,
      -1,
      7,
      9,
      6,
      -1,
      -1,
      -1
    ],
    [
      4,
      3,
      9,
      2,
      5,
      -1,
      9,
      -1,
      -1,
      1
    ]
  ],
  "ideas": [
    [
      null,
      null,
      null,
      "[Safety] Bias Detection in Personalized Recommendation Systems\n\nThis research will develop a novel method for detecting and quantifying bias in personalized recommendation systems by analyzing user behavior across multiple platforms and identifying patterns indicative of unfairness. The system will use a combination of differential privacy techniques and adversarial training to identify and mitigate potential biases related to demographic factors and user preferences. Data will include user interaction logs, explicit feedback, and simulated user profiles. Evaluation will involve measuring fairness metrics such as equal opportunity and demographic parity across different user groups.",
      "[Evaluation] Dynamic Attention Network for Visual Scene Understanding\n\nThis research explores a novel dynamic attention mechanism for visual scene understanding, aiming to improve performance on complex scenes with occlusions and varying object scales. The idea involves extending the standard self-attention mechanism to incorporate a \"contextual memory\" layer that dynamically adjusts the attention weights based on recent visual input. We will evaluate the network on a dataset of human-annotated scenes with varying levels of occlusion and object scale using metrics like Mean Intersection over Union (mIoU) and a custom metric measuring the accuracy of object segmentation.",
      "[NLP] Text-to-Image Style Transfer for Enhanced Narrative Generation\n\nThis project explores the use of a novel text-to-image style transfer technique to dynamically adjust the visual style of generated narratives, enhancing their emotional impact and reader engagement. The system will utilize a diffusion model fine-tuned on a dataset of emotionally-labeled stories, and will evaluate the generated narratives based on human ratings of emotional valence and narrative coherence.",
      "[NLP] Personalized Narrative Generation with Sentiment-Aware Style Adjustment\nThis project investigates a method for generating interactive narratives that dynamically adjust their style based on the user\u2019s emotional response to the story\u2019s content. The system will utilize a transformer model fine-tuned on user-generated stories, incorporating sentiment analysis to identify emotional peaks and valleys. Evaluation will be based on average user ratings and qualitative analysis of user responses.",
      null,
      "[ML] Reinforcement Learning for Dynamic Task Allocation in Simulated Robotics\n\nThis research investigates using reinforcement learning to dynamically allocate tasks within a simulated robotic environment. The goal is to develop an agent that learns to optimize task assignments based on real-time sensor data and the robot\u2019s current state, improving efficiency and reducing operational costs. Data will include sensor readings (e.g., joint angles, force, proximity), task descriptions, and robot performance metrics. Evaluation will be based on task completion time, resource utilization, and the number of errors made during task execution.",
      "[HCI] Personalized Embodied Feedback for Navigation\n\nThis research explores the use of haptic feedback to provide personalized navigational cues for users with visual impairments. We will develop a system that uses a wearable device to deliver subtle vibrations and tactile patterns correlated to the user\u2019s intended movement, allowing them to \u2018feel\u2019 their way through a space. Evaluation will focus on subjective user ratings of ease of navigation, perceived confidence, and reduction in anxiety, using a controlled lab setting with participants with low visual acuity."
    ],
    [
      "[Cognitive Science] Investigating the Neural Correlates of Emotional Resonance in Virtual Companions\n\nThis research will explore the neural activity associated with emotional resonance experienced by users interacting with virtual companions, specifically focusing on the role of mirror neuron systems. I will use fMRI to examine how participants\u2019 brain activity changes when they receive feedback indicating the virtual companion\u2019s emotional state, and correlate these changes with subjective reports of emotional engagement. Data will include fMRI data, self-report questionnaires assessing emotional engagement, and measures of physiological responses (e.g., heart rate variability). Metrics will include accuracy of emotional state prediction and subjective ratings of emotional engagement.",
      "[Safety] Bias Detection in Personalized Recommendation Systems\n\nThis research will develop a novel method for detecting subtle biases embedded within personalized recommendation systems by analyzing the diversity of items presented to users. I will build a system that identifies when a user consistently receives recommendations that are highly similar to those they\u2019ve previously engaged with, even if those recommendations are not explicitly biased. Data will include user interaction history, item metadata, and a measure of similarity between items. Evaluation will involve comparing the system\u2019s detection rate to human annotators and assessing the impact on user satisfaction.",
      "[Evaluation] Federated Learning for Personalized Medical Diagnosis\n\nThis research will explore the feasibility and effectiveness of federated learning for training diagnostic models on medical data distributed across multiple hospitals. I will build a system that allows multiple hospitals to collaboratively train a diagnostic model without sharing their raw patient data, leveraging local model updates to improve overall accuracy. Data will include patient records, imaging data, and clinical notes, and evaluation will be based on diagnostic accuracy, sensitivity, and specificity across different hospitals.",
      "[NLP] Contextualized Sentiment Analysis with Visual Grounding\n\nThis research will develop a system that analyzes sentiment in text by combining contextual understanding with visual cues from an image. The system will use a transformer model to identify sentiment, but will also incorporate visual features (e.g., facial expressions, object recognition) to provide a richer understanding of the sentiment expressed. I will evaluate the system using a held-out dataset of text and images, measuring accuracy and F1-score on sentiment classification and visual similarity.",
      "[Vision]  Interactive Scene Graph Generation for Robotic Manipulation\n\nThis research explores a method for generating interactive scene graphs \u2013 representations of the environment that robots can use to plan and execute manipulation tasks \u2013 leveraging visual information and object properties. It will utilize a graph neural network to learn a representation of the scene, incorporating object attributes and spatial relationships, and then generate a sequence of actions that a robot can execute. Evaluation will be based on the success rate of successful manipulation tasks, measured by the number of successful grasp events and the time taken to complete the task.",
      "[ML] Predictive Maintenance for Wind Turbine Blades using Sensor Data Analysis\n\nThis project investigates the use of machine learning to predict component failures in wind turbine blades using sensor data collected from vibration and temperature sensors. The system will train a recurrent neural network (RNN) on historical sensor data to identify patterns indicative of impending blade failure, allowing for proactive maintenance scheduling. Evaluation will be based on the precision and recall of failure prediction, as well as the reduction in downtime caused by maintenance interventions.",
      null,
      "[HCI] Personalized Embodied Feedback for Navigation Assistance\n\nThis research explores the integration of haptic feedback into a mobile navigation app to provide personalized, contextual guidance. Users will wear a small, lightweight device that delivers subtle vibrations and tactile cues based on their current location and planned route. The system will learn user preferences through a short onboarding phase and adapt feedback based on observed behavior (e.g., avoiding obstacles, quickly finding routes). Evaluation will involve measuring task completion time, user satisfaction (using a Likert scale), and the frequency of successful navigation.",
      null,
      "[HCI] Adaptive Spatial Awareness System for Elderly Individuals\n\nThis research develops a system that utilizes computer vision and machine learning to provide real-time spatial awareness to elderly individuals with cognitive decline. The system will analyze video feeds from a smartphone camera and provide subtle, personalized visual cues \u2013 such as highlighting potential obstacles or guiding the user towards a desired location \u2013 based on their current position and movement. Evaluation will involve assessing the system\u2019s accuracy in identifying and alerting users to potential hazards and measuring the user\u2019s perceived level of spatial awareness through a standardized questionnaire."
    ],
    [
      "[NLP] Personalized Dialogue Style Analysis using Transformer Networks\n\nThis research explores the impact of dialogue style on user engagement and satisfaction in virtual assistants. I will develop a transformer-based model that analyzes user responses to virtual assistants, identifying distinct stylistic patterns (e.g., formal, informal, humorous) and correlating these patterns with user sentiment and task completion rates. Data will include a dataset of user-assistant interactions, labeled with stylistic features and user feedback. Evaluation will be based on user satisfaction scores and task completion time.",
      "[NLP] Contextual Sentiment Shift Detection in Conversational AI\n\nThis research will develop a model that analyzes the sentiment expressed within a conversation, identifying shifts in sentiment that indicate a user is becoming frustrated or dissatisfied with the AI's responses. I will build a model leveraging transformer networks to detect subtle changes in sentiment expressed through word choice, emoji usage, and conversational tone, and will evaluate performance using a held-out dataset of user-AI conversations labeled with sentiment scores.",
      null,
      null,
      null,
      null,
      "[Cognitive Science] Investigating the Impact of Episodic Memory Retrieval on Social Bias Amplification\n\nThis research explores how readily available episodic memories of specific social interactions can inadvertently amplify existing biases towards particular individuals, potentially leading to inaccurate judgments of trustworthiness or competence. Participants will be presented with a series of short, ambiguous social scenarios, and their responses will be analyzed to determine if retrieval of related memories significantly alters their subsequent judgments.  The study will utilize fMRI to examine neural activity associated with bias detection and consolidation.",
      null,
      "[Visualization] Generative Adversarial Networks (GANs) for Realistic Texture Synthesis from Limited Data\n\nThis research investigates the application of Generative Adversarial Networks (GANs) to synthesize realistic textures from small, sparse datasets. The approach will involve training a GAN to generate textures conditioned on a limited set of visual examples, allowing for the creation of novel materials and surfaces. Evaluation will focus on perceptual quality metrics (e.g., LPIPS) and the ability to generate textures that closely match the characteristics of provided reference images.",
      "[Vision] Interactive Narrative Generation with Visual Storytelling\n\nThis research explores the use of a conditional generative model to dynamically generate visual story elements (e.g., character poses, environment details, object appearances) based on a user's textual input, creating an interactive narrative experience. I will leverage a transformer-based model to map textual descriptions to visual representations, incorporating a reinforcement learning component to optimize for user engagement and coherence. Data will include a dataset of short narrative scenes and corresponding visual representations. Evaluation will be based on user ratings of narrative coherence, visual appeal, and engagement metrics derived from user interaction."
    ],
    [
      "[NLP] Knowledge Graph-Enhanced Sentiment Analysis for Social Media\nThis research proposes a novel approach to sentiment analysis by integrating knowledge graphs to improve the accuracy and interpretability of models. The system will leverage Wikidata and other knowledge sources to provide contextualized sentiment information, enhancing the model\u2019s ability to understand nuanced user expressions. Evaluation will be based on F1-score and a metric assessing the coherence of the model\u2019s sentiment predictions with the knowledge graph\u2019s representation of the social media context.",
      null,
      null,
      "[HCI] Personalized Embodied Feedback for Navigation Assistance\n\nThis research explores the integration of haptic feedback into a mobile navigation app to provide users with more intuitive and personalized guidance. We will develop a system that uses subtle vibrations to indicate the direction of movement and potential obstacles, tailored to the user\u2019s gait and preferred navigation style. The system will be evaluated through user studies measuring task completion time, error rates, and subjective ratings of comfort and ease of use. Metrics will include frequency of successful navigation and user reported feelings of confidence.",
      null,
      "[Safety] Explainable AI for Automated Loan Denial Decisions\n\nThis research focuses on developing methods to provide transparency and justification for automated loan denial decisions, addressing concerns about fairness and potential discrimination. We will build a system that analyzes loan application data (including applicant demographics, credit history, and income) and generates a detailed, human-readable explanation of the factors contributing to the denial, using techniques like rule-based reasoning and potentially incorporating fairness metrics. Evaluation will involve comparing the system\u2019s explanations to those provided by human loan officers and assessing their accuracy and comprehensibility.",
      "[NLP] Personalized Narrative Generation for User Engagement\n\nThis research will develop a system that generates unique, personalized narratives tailored to individual user preferences and emotional states, using a combination of sentiment analysis and reinforcement learning. The system will analyze user activity and emotional responses to dynamically adjust the narrative's tone, complexity, and content, aiming to increase user engagement and satisfaction.",
      "[Vision] Visual Grounding for Dialogue: Exploring Contextualized Visual Anchors for Conversational Agents. This research will develop a system that allows conversational agents to reliably ground their responses in visual context \u2013 specifically, using a small set of pre-defined visual anchors (e.g., a specific object, a room scene) to improve coherence and understanding of user intent. We will evaluate the system using a user study where participants are asked to complete tasks requiring visual reasoning, measuring accuracy and perceived coherence.",
      null,
      "[NLP] Contextual Sentiment Analysis of Scientific Literature for Accelerated Discovery\n\nThis research investigates the use of a fine-tuned transformer model to automatically analyze scientific publications and identify key concepts, relationships, and potential research directions. The model will be trained on a corpus of peer-reviewed papers across various disciplines, focusing on identifying emerging themes and highlighting areas of active investigation. Evaluation will be based on precision and recall of relevant concepts, as well as the coherence and readability of the identified insights."
    ],
    [
      "[NLP] Explainable Sentiment Analysis with Attention-Based Graph Embedding\nThis research explores using attention mechanisms to enhance explainability in sentiment analysis models, particularly by incorporating graph embeddings derived from knowledge graphs. The model will be trained on a dataset of social media posts, and explainability will be evaluated using methods like SHAP and LIME, focusing on identifying the most influential entities driving sentiment predictions.",
      "[HCI] Personalized Embodied Navigation Assistance for Elderly Users\n\nThis research will develop a mobile application that uses computer vision and natural language processing to provide personalized navigation assistance to elderly users, leveraging their preferred routes and spatial awareness. The app will utilize a combination of visual landmark recognition and conversational AI to offer step-by-step instructions and anticipate potential obstacles, incorporating user feedback to continuously improve the experience. Evaluation will be based on task completion rate, user satisfaction (measured through surveys), and fall risk reduction.",
      "[Cognitive Science] Exploring the Role of Implicit Social Evaluation in Episodic Memory Consolidation \u2013 A Longitudinal Study\n\nThis research will conduct a longitudinal study examining the impact of repeated implicit social evaluation on episodic memory consolidation. We will use fMRI to assess neural activity during simulated social interactions, tracking changes in brain regions associated with reward processing and social cognition. The goal is to determine if repeated implicit evaluations of a person\u2019s behavior strengthen the encoding of relevant episodic memories, leading to improved recall and a more robust understanding of how social evaluation shapes memory formation. Data will include behavioral measures of social evaluation (e.g., facial expressions, verbal comments) and fMRI data capturing neural responses to simulated social interactions.",
      "[NLP] Sentiment-Aware Dialogue Generation for Crisis Support\n\nThis research aims to develop a dialogue agent that dynamically adjusts its response style based on the user\u2019s expressed emotional state, improving the effectiveness of crisis support conversations. We will utilize a transformer model fine-tuned on a dataset of crisis conversations and incorporate a sentiment analysis module to monitor the user\u2019s emotional cues. Evaluation will be based on user satisfaction scores and a measure of crisis resolution success.",
      "[NLP] Contextualized Dialogue State Tracking with Attention\n\nThis research explores the use of attention mechanisms to improve the contextual understanding of dialogue states within a large language model. We will develop a system that dynamically weights different parts of the dialogue history based on their relevance to the current turn, enhancing the model\u2019s ability to track user goals and intentions across longer conversations. Data will be collected through a series of simulated dialogues, and evaluation will be based on task completion rate and user satisfaction scores.",
      "[Vision] Visual Grounding for Dialogue Response Generation\n\nThis research investigates the integration of visual cues (e.g., facial expressions, body posture) with textual dialogue to improve the coherence and naturalness of response generation. We will develop a model that learns to associate visual features with specific dialogue intents, enabling the system to better understand the user\u2019s emotional state and intentions, leading to more engaging and relevant responses. Evaluation will be conducted using a dataset of multi-modal dialogues, focusing on metrics like user engagement and task completion rate.",
      "[NLP] Contextualized Dialogue State Tracking with Attention\n\nThis research explores a novel approach to dialogue state tracking that leverages attention mechanisms to dynamically weight the importance of different contextual cues during response generation. It builds upon the existing work of incorporating visual cues into dialogue understanding, but instead of relying solely on facial expressions, it focuses on analyzing body posture and gestures to refine the model\u2019s understanding of the user\u2019s emotional state and intent. We will evaluate the model\u2019s performance on a benchmark dataset of multi-turn conversations, measuring metrics such as coherence, relevance, and user satisfaction.",
      "[NLP] Personalized Knowledge Graph Construction for Scientific Discovery\n\nThis research will develop a system that automatically constructs personalized knowledge graphs for researchers based on their current research interests and publications. The system will leverage a combination of text mining, citation analysis, and knowledge graph embedding techniques to identify relevant entities and relationships, and then iteratively refine these graphs to reflect the researcher\u2019s evolving understanding of the field. We will evaluate the quality of the generated knowledge graphs using metrics such as coverage, coherence, and novelty, and assess their impact on research productivity through user surveys.",
      "[NLP] Contextual Sentiment Analysis of Social Media Posts for Proactive Crisis Detection",
      null
    ],
    [
      null,
      "[Safety] Algorithmic Bias Detection in Autonomous Vehicle Perception Systems\n\nThis research will develop a novel framework for detecting and quantifying algorithmic bias in pedestrian detection models used by autonomous vehicles. The framework will leverage a combination of adversarial training and explainable AI (XAI) techniques to identify subtle biases that might lead to disproportionate risk assessments for certain demographic groups. Data will include a diverse set of pedestrian datasets augmented with simulated adversarial examples generated using a modified adversarial attack algorithm. Evaluation will be based on metrics like false positive rate and disparate impact analysis, focusing on the fairness of risk assessment across different demographic groups.",
      null,
      "[NLP] Visual-Textual Sentiment Alignment for Enhanced Dialogue Quality\n\nThis research explores how visual cues (e.g., facial expressions in videos, objects in images) can be integrated with textual dialogue to improve the coherence and emotional resonance of conversations. We will develop a model that analyzes both the text and visual data to predict the user's emotional state and adjust the dialogue accordingly, leveraging a transformer model trained on paired visual and textual data. We will evaluate the model\u2019s performance using metrics like coherence score and user ratings of emotional engagement.",
      "[NLP] Knowledge Graph Completion with Adversarial Training for Enhanced Reasoning\n\nThis research explores the use of adversarial training to improve the accuracy and robustness of knowledge graph completion. We will train a model to predict missing relationships between entities in a knowledge graph, incorporating an adversarial component that encourages the model to generate plausible but incorrect completions. We will evaluate the model on benchmark knowledge graphs and human-annotated datasets using metrics like accuracy and consistency.",
      "[NLP] Contextualized Sentiment Analysis for Scientific Report Generation\n\nThis research aims to develop a system that automatically generates concise and informative summaries of scientific reports, incorporating contextual sentiment analysis to ensure the report accurately reflects the author's intended message and audience. We will use a transformer-based model fine-tuned on a dataset of scientific reports and their associated sentiment scores. Evaluation will be based on human assessment of report clarity, accuracy, and persuasiveness, as well as automated metrics like ROUGE and BLEU for summarization quality.",
      null,
      null,
      "[NLP] Interactive Narrative Simulation for Emotional Regulation\n\nThis research explores the use of a reinforcement learning agent to simulate emotionally challenging narrative scenarios, designed to improve emotional regulation skills in users. The agent will respond to user choices within a dynamically generated story, providing feedback on emotional states and guiding the user towards more adaptive responses. We will evaluate the agent\u2019s effectiveness using a combination of physiological data (heart rate variability) and self-reported emotion ratings, focusing on improvements in anxiety and stress reduction.",
      null
    ],
    [
      null,
      null,
      "[NLP] Contextualized Sentiment Analysis of Social Media Posts\n\nThis research explores the development of a novel contextualized sentiment analysis model that goes beyond simple polarity detection by incorporating discourse-level cues and emotional tone. The model will be trained on a large dataset of social media posts, utilizing a transformer architecture augmented with a discourse parsing module. Evaluation will be based on a combination of accuracy (measured by F1-score) and a novel metric, \u201cEmotional Resonance Score\u201d (ERS) which quantifies the degree to which the model\u2019s sentiment prediction aligns with the expressed emotional tone within the post.",
      "[NLP] Explainable Sentiment Analysis for Customer Service Interactions\n\nThis research investigates the development of an explainable sentiment analysis model specifically tailored for analyzing customer service interactions (e.g., chat logs, call transcripts). The model will leverage attention mechanisms to highlight the parts of the text that contribute most to the sentiment, and will provide insights into *why* a customer is expressing a particular sentiment. Data will be collected from a simulated customer service platform, and evaluation will be based on metrics like precision, recall, and F1-score, alongside human evaluation of the model\u2019s explanations.",
      "[NLP] Contrastive Learning for Bias Detection in Large Language Models\n\nThis research will develop a novel contrastive learning framework to automatically identify and quantify biases present in large language models (LLMs) across various demographic groups. We will train a model to learn positive and negative examples of text associated with different protected attributes (e.g., gender, race) and then use this learned representation to flag potentially biased outputs. Evaluation will be based on metrics like precision, recall, and F1-score across different demographic groups.",
      "[HCI] Embodied Conversational Agents for Mental Health Support",
      "[NLP] Knowledge-Aware Dialogue Generation with Episodic Memory\n\nThis research develops a dialogue generation system that incorporates episodic memory \u2013 the ability to recall and utilize past interactions \u2013 to improve coherence and engagement. The system will train a transformer model on a dataset of multi-turn dialogues, incorporating a memory module that stores and retrieves relevant past utterances and responses. Evaluation will focus on metrics like turn coherence, user engagement (measured through conversation length and user ratings), and the ability to maintain consistent character traits across multiple turns.",
      null,
      "[NLP] Personalized Dialogue Generation with Contextual Memory\n\nThis research explores the use of a transformer-based model to generate dialogue for virtual assistants, incorporating a memory network to retain and utilize past conversation history. We will evaluate the model\u2019s ability to maintain coherence and relevance across extended conversations, focusing on metrics like user satisfaction and task completion rate.  Neighbor (6, 9) [score=0.76, last_updated=4] provides a strong foundation for dialogue generation, and this extension will build upon its ability to maintain context and personalize responses.",
      "[NLP] Interactive Storytelling with Dynamic Character Reactions\nThis research investigates the use of reinforcement learning to dynamically adjust character reactions and dialogue based on player choices within interactive stories, enhancing immersion and narrative engagement. We will develop a system that learns to respond to player actions in real-time, generating believable and evolving character dialogue and behavior, utilizing a combination of natural language understanding and reinforcement learning."
    ],
    [
      "[NLP] Contextualized Sentiment Analysis of Social Media Posts\n\nThis research explores the development of a novel contextualized sentiment analysis model that goes beyond simple polarity detection by incorporating discourse-level cues and emotional tone. The model will be trained on a large dataset of social media posts, utilizing a transformer architecture augmented with a discourse parsing module to identify key phrases and relationships between sentences. Evaluation will be based on a held-out test set measuring accuracy, precision, recall, and F1-score, comparing against a baseline model trained on standard sentiment analysis techniques.",
      null,
      null,
      "[HCI] Personalized Emotional Response Mapping for Virtual Assistants\n\nThis research explores the design of a system that allows virtual assistants to dynamically map the emotional state of a user based on their verbal and non-verbal communication, providing a more empathetic and responsive interaction. The system will utilize a combination of speech emotion recognition (SER) and facial expression analysis, trained on a diverse dataset of user interactions. Evaluation will be based on user satisfaction ratings and a subjective measure of perceived empathy.",
      "[Cognitive Science] Exploring the Role of Predictive Coding in Social Memory Consolidation\n\nThis research investigates whether predictive coding mechanisms within the hippocampus play a crucial role in consolidating social memories, specifically those involving emotional context and perceived threat. I will build a computational model simulating the hippocampus\u2019s activity during the replay of social interactions, using a combination of fMRI data and behavioral measures of emotional response. The model will focus on predicting the next state of the social interaction based on past experiences, and will evaluate its ability to improve the accuracy of recall of emotionally charged social events compared to a control group with no predictive coding simulation.",
      "[HCI] Interactive Narrative Simulation for Trauma Recovery\n\nThis research develops an interactive narrative experience designed to help individuals process traumatic memories through a carefully constructed, branching story. The system will utilize NLP to generate dynamic responses based on user choices, incorporating elements of cognitive behavioral therapy (CBT) principles. Evaluation will be based on standardized trauma assessment tools and subjective user reports of emotional regulation and narrative engagement.",
      "[Vision]  Generative Adversarial Networks (GANs) for Synthetic Image Data Augmentation for Medical Image Segmentation\n\nThis research proposes a novel GAN architecture specifically designed to generate synthetic medical images with high fidelity, addressing the scarcity of labeled medical data. The GAN will be trained on a dataset of real medical images and will generate variations of existing images, including simulated lesions, anatomical variations, and different imaging modalities.  Evaluation will be based on metrics like Intersection over Union (IoU) and Dice coefficient, comparing the performance of the synthetic data on a downstream segmentation task (e.g., tumor segmentation).",
      null,
      "[NLP] Interactive Narrative Simulation with Dynamic Character Alignment\n\nThis research investigates the development of a system that allows for the creation of interactive narratives where character alignment and emotional consistency are dynamically adjusted based on user feedback and contextual information. We will use a reinforcement learning approach to train a model to predict and influence character behavior, incorporating a user-defined emotional profile and a real-time analysis of narrative events. Evaluation will be based on user ratings of narrative coherence, emotional engagement, and character believability, measured using a Likert scale.",
      "[NLP] Personalized Knowledge Synthesis via Contextual Attention Networks\n\nThis research explores the use of a novel attention mechanism to enhance knowledge synthesis within large language models. We will develop a system that dynamically prioritizes and integrates relevant information from a user's past interactions and contextual knowledge base, improving the accuracy and relevance of generated summaries and explanations. We will evaluate the system using a benchmark dataset of scientific papers and user-provided questions, measuring coherence, factual correctness, and user satisfaction."
    ],
    [
      null,
      "[HCI] Context-Aware Navigation Assistance with Predictive Vibration Feedback\n\nThis research develops a mobile navigation app that dynamically adjusts route recommendations based on the user\u2019s observed gait and predicted movement patterns, utilizing subtle vibration feedback to provide a more intuitive and personalized experience. The system will integrate accelerometer and gyroscope data to forecast the user\u2019s next steps, offering proactive guidance and minimizing disorientation. Evaluation will involve user studies measuring task completion time, error rates, and subjective comfort ratings. Metrics will include frequency of successful navigation and user reported feelings of confidence.",
      "[HCI] Personalized Embodied Navigation via Predictive Vibration Mapping\n\nThis research explores the integration of haptic feedback into a mobile navigation app to provide users with more intuitive and personalized guidance. We will develop a system that uses subtle vibrations to indicate the direction of movement and potential obstacles, tailored to the user\u2019s gait and preferred navigation style. The system will leverage gait data collected through IMUs and user feedback on navigation accuracy. Evaluation will be based on subjective user ratings of navigation clarity and perceived ease of use, as well as objective metrics like time to reach destination and error rate.",
      null,
      "[NLP] Interactive Storytelling with Emotional Response Adaptation\n\nThis research will develop an interactive storytelling platform that dynamically adjusts the narrative based on the user\u2019s emotional state, utilizing a transformer model to analyze sentiment and adjust plot points, character interactions, and emotional cues in real-time. Evaluation will be based on user engagement metrics (time spent, completion rate), subjective ratings of emotional impact, and a validated emotion recognition scale.",
      "[NLP] Personalized Emotional Feedback System for Creative Writing\n\nThis research will develop a system that analyzes a writer\u2019s creative text \u2013 including prose, poetry, and scripts \u2013 to provide personalized feedback on emotional tone and engagement, using a transformer model to identify and quantify emotional states. Evaluation will be based on subjective human ratings of emotional impact and stylistic coherence, measured using a Likert scale.",
      "[NLP] Knowledge Graph Completion with Adaptive Reasoning\n\nThis research investigates the use of knowledge graph completion (KGC) techniques augmented with adaptive reasoning to improve the accuracy and robustness of question answering systems. Current KGC methods often rely on fixed reasoning rules, failing to handle complex, multi-hop queries. We propose a system that dynamically adjusts the reasoning path based on the uncertainty in the knowledge graph and the user's question, leveraging a probabilistic reasoning framework. Evaluation will be conducted on benchmark question answering datasets, measuring accuracy and efficiency.",
      null,
      null,
      null
    ],
    [
      "[Cognitive Psychology] Adaptive Route Guidance via Predictive Attention\n\nThis research investigates how visual attention shifts during route navigation, and how this shifts can be leveraged to improve route adherence and reduce cognitive load. It will develop a system that analyzes visual attention patterns (using eye-tracking) and dynamically adjusts route recommendations to capitalize on periods of heightened attention, promoting more consistent route following. Data will include eye-tracking data, route tracking data, and user-reported attention levels. Evaluation will be based on subjective user ratings of route adherence and perceived cognitive effort.",
      "[HCI] Dynamic Route Adaptation via Predictive Motion Analysis\n\nThis research investigates a system that uses predictive motion analysis to dynamically adjust route recommendations in real-time, based on the user\u2019s observed gait and anticipated movement patterns. It leverages a combination of accelerometer and gyroscope data to forecast the user\u2019s next steps, offering a more personalized and proactive navigation experience. We will evaluate the system\u2019s effectiveness through a series of controlled trials with diverse user groups, measuring metrics such as route completion time, user satisfaction, and adherence to preferred navigation styles.",
      "[NLP] Contextualized Dialogue Generation for Emergency Response\n\nThis research explores the use of a transformer model to generate empathetic and informative dialogue responses in emergency situations, leveraging real-time sensor data (e.g., location, audio) to tailor responses to the user\u2019s immediate needs. Data will include recorded emergency calls and associated sensor readings. Evaluation will be based on user satisfaction (measured via a post-call survey) and the accuracy of the generated responses in conveying relevant information.",
      "[NLP] Visual-Textual Sentiment Alignment for Crisis Prediction\n\nThis research will develop a system that aligns visual and textual sentiment expressed in social media posts with a specific crisis event, using a transformer model to identify correlations between image and text cues. The system will leverage a dataset of social media posts and corresponding images, and evaluate performance using a custom metric combining precision and recall on crisis prediction tasks.",
      "[NLP] Dynamic Crisis Prediction via Multi-Modal Sentiment Fusion\nThis research will develop a system that predicts potential crises by fusing sentiment analysis from social media posts with visual cues (e.g., image analysis) and textual context, leveraging a transformer model to dynamically adjust the weighting of each modality. Evaluation will be based on precision and recall for identifying emerging crisis indicators, as well as a user-defined metric of time to detection.",
      null,
      "[NLP] Contrastive Learning for Explainable AI\n\nThis research explores using contrastive learning to improve the explainability of deep learning models by generating synthetic data that highlights the model's decision-making process. It leverages a pre-trained language model to create pairs of inputs and their corresponding explanations, allowing for a more granular understanding of how the model arrives at its predictions. Data: A dataset of image classification tasks with corresponding human-generated explanations. Evaluation:  Metrics like BLEU score and human evaluation of explanation quality.",
      null,
      null,
      "[Safety] Algorithmic Bias Detection in Autonomous Vehicle Perception Systems\n\nThis research will develop a novel framework for detecting and quantifying algorithmic bias in pedestrian detection models used by autonomous vehicles. The framework will leverage a combination of adversarial training and explainable AI (XAI) techniques to identify disparities in detection rates across demographic groups (e.g., based on age, race, and gender). We will evaluate the framework using a publicly available dataset of pedestrian images and metrics such as precision, recall, and F1-score, focusing on identifying patterns indicative of biased model behavior."
    ]
  ]
}