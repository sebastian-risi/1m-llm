{
  "scores": [
    [
      0.8382128019758843,
      0.0,
      0.8433943074655427,
      0.8694036075945153,
      0.7704284288441505,
      0.630385344126937,
      0.6569710748944159,
      0.0,
      0.8753223684210527,
      0.783688386119373
    ],
    [
      0.7657246420328864,
      0.7639348966479313,
      0.6935052443224272,
      0.8389057524001601,
      0.7357164016462813,
      0.8255714497307486,
      0.0,
      0.8125,
      0.8490225394705062,
      0.6736208779534252
    ],
    [
      0.7887861917420973,
      0.8520023900192237,
      0.0,
      0.0,
      0.7888753610985636,
      0.0,
      0.5738500570027243,
      0.6254444315034554,
      0.7239778571428571,
      0.7035410169461747
    ],
    [
      0.8085727934242704,
      0.0,
      0.8360346831885539,
      0.8375,
      0.8387475490196079,
      0.7372301401869159,
      0.684964110314398,
      0.8321887159932965,
      0.7421907069869512,
      0.7981233169462116
    ],
    [
      0.7789708211019445,
      0.789825766468008,
      0.5413268222044059,
      0.40327724828934514,
      0.6943075091708347,
      0.82462378383769,
      0.6897579787234043,
      0.40383254933726187,
      0.7359474111615932,
      0.0
    ],
    [
      0.7167275814468468,
      0.6992850703938078,
      0.0,
      0.8077292917956657,
      0.7555003331784457,
      0.8456118421052632,
      0.7697533913235887,
      0.7515050986247146,
      0.8209887281750381,
      0.0
    ],
    [
      0.829137949039265,
      0.7648812171209948,
      0.8364371006029416,
      0.795375,
      0.7946409900072345,
      0.40845611842105267,
      0.7977655497887588,
      0.7499148849351169,
      0.7785916930058123,
      0.7073992958187473
    ],
    [
      0.804124712823726,
      0.0,
      0.813875749292821,
      0.7916812409963986,
      0.609593195192715,
      0.7579507236622053,
      0.7950998574209996,
      0.0,
      0.8123389486741801,
      0.6607756668858547
    ],
    [
      0.0,
      0.6174185482109423,
      0.6898843602535745,
      0.0,
      0.40420800919474603,
      0.6877350359014044,
      0.8489950300256605,
      0.0,
      0.0,
      0.6941073747680891
    ],
    [
      0.7254138368585482,
      0.7556694001405199,
      0.7484134437693716,
      0.7306426862479309,
      0.7308784388544474,
      0.39591545505855813,
      0.8693232836335899,
      0.7679104045535077,
      0.0,
      0.8625
    ]
  ],
  "last_updated": [
    [
      19,
      -1,
      11,
      14,
      18,
      18,
      14,
      -1,
      11,
      16
    ],
    [
      19,
      15,
      14,
      5,
      13,
      17,
      -1,
      10,
      17,
      11
    ],
    [
      15,
      16,
      -1,
      -1,
      13,
      -1,
      16,
      18,
      10,
      10
    ],
    [
      16,
      -1,
      16,
      4,
      10,
      8,
      9,
      15,
      18,
      8
    ],
    [
      18,
      19,
      13,
      13,
      13,
      11,
      3,
      17,
      11,
      -1
    ],
    [
      16,
      15,
      -1,
      6,
      17,
      5,
      19,
      18,
      17,
      -1
    ],
    [
      17,
      12,
      19,
      3,
      16,
      8,
      14,
      19,
      17,
      18
    ],
    [
      19,
      -1,
      17,
      9,
      13,
      6,
      10,
      -1,
      7,
      15
    ],
    [
      -1,
      8,
      9,
      -1,
      19,
      9,
      6,
      -1,
      -1,
      10
    ],
    [
      16,
      14,
      16,
      19,
      5,
      17,
      9,
      18,
      -1,
      1
    ]
  ],
  "ideas": [
    [
      "[NLP] Contextual Storytelling Adaptation: Evaluating the Effectiveness of Dynamic Narrative Generation on User Retention in Virtual Training Simulations.\nThis research will investigate how dynamically adapting narrative elements (character traits, plot twists, world events) within a virtual training simulation impacts user engagement and retention. We will measure retention rates, task completion times, and subjective user feedback (using questionnaires) to assess the impact of this adaptation. Data will include physiological data (heart rate variability) during simulation sessions.",
      null,
      "[NLP] Contextual Sentiment Analysis of Social Media Posts for Mental Health Support\n\nThis research will develop a novel model for analyzing social media posts to identify patterns and sentiment associated with mental health struggles, using a transformer-based architecture. It will leverage a pre-trained model and fine-tune it on a dataset of publicly available social media content, focusing on identifying keywords and phrases indicative of distress. Evaluation will be based on accuracy in sentiment classification and the ability to detect emerging trends in mental health discussions.",
      "[Safety] Federated Learning for Personalized Privacy Protection\n\nThis research will explore federated learning techniques to train personalized privacy protection models without directly sharing sensitive user data. The system will utilize differential privacy mechanisms and secure aggregation protocols to train models locally on each user\u2019s device, preserving privacy while still benefiting from personalized features. Data will include user activity logs and device information, and evaluation will focus on accuracy and privacy loss.",
      "[NLP] Contextualized Story Generation with Adaptive Persona Modeling\nThis research proposes a novel NLP approach to contextualized story generation, incorporating adaptive persona modeling to maintain consistent character traits and narrative voice across evolving storylines. It will utilize a transformer-based model fine-tuned on a dataset of interactive fiction, evaluating coherence, character consistency, and engagement through human ratings and automated metrics like perplexity and narrative length.",
      "[NLP] Interactive Storytelling with Dynamic Visual Style Adaptation\nThis project explores a system that dynamically adjusts the visual style of interactive narratives based on the user\u2019s emotional response, leveraging a diffusion model and reinforcement learning to create a more immersive and emotionally resonant experience. It will focus on enhancing narrative coherence and engagement through adaptive visual cues.",
      "[NLP] Personalized Narrative Coherence via Emotional Resonance Modeling\nThis project explores a novel approach to interactive storytelling by dynamically adjusting the narrative style based on the user\u2019s emotional response to the story\u2019s content. The system will utilize a transformer model fine-tuned on user-generated stories, incorporating sentiment analysis to identify emotional peaks and valleys. Evaluation will be based on average user ratings and qualitative analysis of user responses.",
      null,
      "[ML] Adversarial Training for Robust Object Detection in Low-Light Conditions\n\nThis research focuses on developing robust object detection models that perform reliably in challenging low-light environments. We will explore adversarial training techniques to improve the model\u2019s resilience to noise and illumination variations, potentially enhancing performance in applications like autonomous driving or surveillance. Data will include a diverse set of images captured in varying lighting conditions, and evaluation will be based on mean Average Precision (mAP) across multiple low-light scenarios.",
      "[HCI] Context-Aware Navigation Assistant for Seniors with Fall Risk\n\nThis research develops a mobile application that provides contextual navigation assistance to seniors, incorporating real-time sensor data (IMUs, cameras) and personalized risk assessments to proactively mitigate fall risks. The system will utilize machine learning to predict potential falls based on gait patterns and environmental factors, offering gentle guidance and alerts to the user and caregivers. Evaluation will involve a randomized controlled trial with seniors, measuring fall incidence, navigation accuracy, and user satisfaction."
    ],
    [
      "[Cognitive Science] Embodied Emotional Response Modeling with Virtual Agents\n\nThis research will develop a novel framework for modeling embodied emotional response in virtual agents, integrating visual and physiological data to create a more nuanced understanding of user emotional states. We will use a hierarchical reinforcement learning approach to train an agent to generate responses that are not only engaging but also accurately reflect the user\u2019s underlying emotional state, incorporating both visual cues and physiological data. Metrics will include accuracy of emotional state prediction and subjective ratings of emotional engagement.",
      "[Safety] Adversarial Robustness in Personalized Recommendation Systems\n\nThis research will develop a novel defense mechanism against adversarial attacks targeting personalized recommendation systems, focusing on detecting subtle manipulations of user preferences through adversarial examples. We will build a system that analyzes user interaction data and identifies anomalous patterns indicative of adversarial input, leveraging techniques like adversarial training and anomaly detection. Evaluation will involve testing the system's robustness against various adversarial attack strategies and measuring its ability to correctly classify genuine user preferences.",
      "[NLP] Knowledge Graph Enhanced Sentiment Analysis for Customer Feedback\n\nThis research will develop a knowledge graph-enhanced sentiment analysis system that leverages external knowledge graphs to improve the accuracy and contextual understanding of sentiment analysis performed on customer feedback. It will build a system that identifies sentiment not just based on text, but also on relationships and entities within the knowledge graph, allowing for more nuanced and accurate interpretations of customer opinions. Data will include customer feedback, product reviews, and related knowledge graph data, and evaluation will be based on precision, recall, and F1-score across different sentiment categories.",
      "[NLP] Contextualized Sentiment Analysis with Visual Grounding\n\nThis research will develop a system that analyzes sentiment in text by combining contextual understanding with visual cues from an image. The system will use a transformer model to identify sentiment, but will also incorporate visual features (e.g., facial expressions, object recognition) to provide a richer understanding of the sentiment expressed. I will evaluate the system using a held-out dataset of text and images, measuring accuracy and F1-score on sentiment classification and visual similarity.",
      "[Vision]  Visual-Guided Robot Manipulation Planning with Implicit Scene Understanding\n\nThis research investigates a method for robot manipulation planning that leverages implicit scene understanding \u2013 inferred relationships between objects and their environment \u2013 to guide action selection. It will utilize a visual transformer to learn a representation of the scene, incorporating object properties and spatial relationships, and then generate a sequence of actions that a robot can execute, improving robustness to partial observations. Evaluation will be based on success rate of successful manipulation tasks, measured by the number of successful grasp events and the time taken to complete the task.",
      "[ML] Personalized Irrigation Scheduling using Soil Moisture and Weather Data\n\nThis project aims to develop a system that uses soil moisture sensors and weather data to automatically adjust irrigation schedules for agricultural fields, optimizing water usage and minimizing water waste. The system will utilize a recurrent neural network (RNN) to learn patterns in soil moisture, weather conditions, and crop water needs, allowing for adaptive irrigation strategies. Evaluation will be based on water savings, crop yield, and the accuracy of irrigation recommendations compared to traditional methods.",
      null,
      "[HCI] Dynamic UI Adaptation for Multi-Modal Navigation: Leveraging Eye-Tracking and Contextual Audio\n\nThis research investigates how dynamic UI adaptation can be implemented within a mobile navigation app to optimize user experience, particularly in complex or ambiguous environments. It will develop a system that adjusts the app\u2019s visual layout and audio cues based on real-time eye-tracking data and contextual audio cues (e.g., traffic noise, pedestrian presence) to reduce cognitive load and improve route adherence. Evaluation will involve measuring task completion rates, user error rates, and subjective user ratings of usability and comfort.",
      "[NLP] Contextual Sentiment Analysis of Social Media Posts for Mental Health Monitoring\n\nThis research will develop a system that analyzes social media posts (Twitter, Reddit) to detect shifts in sentiment related to mental health, using Natural Language Processing techniques. The system will employ pre-trained sentiment analysis models and fine-tune them on a dataset of mental health-related posts. Evaluation will be based on the accuracy of sentiment classification and the ability to identify emerging trends in user experiences.",
      "[Safety] AI-Powered Predictive Hazard Detection in Public Spaces\n\nThis research explores the development of an AI system that analyzes video feeds from public spaces to predict and alert users to potential safety hazards \u2013 such as dropped objects, obscured pathways, or unusual activity \u2013 using object recognition and behavioral analysis. The system will leverage a combination of computer vision, natural language processing, and risk assessment algorithms to provide proactive warnings, improving situational awareness and reducing the risk of accidents. Evaluation will involve testing the system\u2019s accuracy in predicting hazards and measuring the effectiveness of the alerts in preventing incidents through a simulated public space environment."
    ],
    [
      "[NLP] Adaptive Persona Generation for Virtual Assistants using Reinforcement Learning\n\nThis research will develop an adaptive persona generation system for virtual assistants, using reinforcement learning to optimize the assistant\u2019s personality and communication style based on user feedback. The system will learn to generate responses that are both engaging and aligned with the user\u2019s expressed preferences, improving user satisfaction and perceived helpfulness. Data will include user interaction logs and explicit feedback on persona attributes. Evaluation will be based on user satisfaction scores and task completion rates.",
      "[NLP] Multi-Modal Sentiment Fusion for Enhanced Dialogue Understanding\n\nThis research will develop a system that fuses textual and visual cues (e.g., facial expressions, emojis) to improve the accuracy of sentiment analysis in virtual assistants, leveraging a transformer-based model to dynamically weight the contributions of each modality. I will build a system that analyzes user facial expressions and emojis alongside the text of the conversation, and will evaluate performance using a held-out dataset of user-assistant interactions labeled with sentiment scores.",
      null,
      null,
      "[NLP] Explainable Sentiment Analysis for Dialogue Systems\n\nThis research aims to develop a novel explainable sentiment analysis method for dialogue systems, going beyond simple polarity scores to provide insights into *why* a system expresses a particular sentiment. We will use a contrastive learning approach, training a model to predict the sentiment of a response based on the context of the dialogue and the user's previous utterances. The model will be evaluated using metrics like accuracy, F1-score, and human evaluation of interpretability.",
      null,
      "[Cognitive Science] Exploring the Role of Predictive Coding in Social Memory Consolidation\n\nThis research investigates how predictive coding mechanisms influence the consolidation of social memories \u2013 memories of interactions with specific individuals. I will design a controlled experiment using a virtual environment where participants are presented with a series of short, ambiguous social interactions. Participants will be asked to rate the emotional valence of each interaction and to predict the participant\u2019s next action. I will then analyze the neural activity in the prefrontal cortex during these predictions, looking for patterns that correlate with the strength of the memory trace. The goal is to determine if predictive coding biases memory consolidation towards more emotionally salient and predictable social events.",
      "[NLP] Explainable AI for Personalized Recommendation Systems - Develop a method to provide users with a transparent rationale behind each recommendation, highlighting the specific features of items that influenced the suggestion. Data will include user interaction history, item features, and recommendation outcomes. Evaluation will involve user ratings of recommendation relevance and perceived trustworthiness.",
      "[Visualization] Procedural Texture Generation with Style Transfer and Reinforcement Learning for Low-Resolution Data\n\nThis research proposes a framework for generating high-quality textures from limited data using a combination of procedural techniques and reinforcement learning. The system will train a neural network to map a small set of input images (e.g., low-resolution scans) to a target texture, guided by a reinforcement learning agent that learns to optimize texture quality based on user feedback. Evaluation will be based on perceptual quality metrics (e.g., LPIPS) and the ability to generate textures that closely match the characteristics of provided reference images.",
      "[Vision] Personalized Emotional Response Generation through Visual Cue Integration\n\nThis research investigates the integration of visual cues \u2013 specifically facial expressions and body language \u2013 with a multimodal model to generate personalized emotional responses in interactive narratives. The model will learn to associate specific visual patterns with corresponding emotional states, allowing for dynamic adaptation of the narrative\u2019s tone and pacing based on the user\u2019s emotional state. Data will include a dataset of human interactions with narratives, annotated with emotional labels and corresponding visual cues. Evaluation will be based on user ratings of emotional engagement and narrative coherence."
    ],
    [
      "[NLP] Knowledge Graph-Guided Dialogue Refinement for Virtual Assistants\nThis research proposes a system that utilizes knowledge graphs to dynamically refine dialogue responses in virtual assistants, improving coherence and relevance to user intent. The system will analyze user utterances and the knowledge graph to identify potential inconsistencies or ambiguities, suggesting alternative dialogue paths and refining responses to ensure a more natural and helpful interaction. Evaluation will be based on user satisfaction scores and task completion rates.",
      null,
      "[ML] Investigating Few-Shot Learning for Object Detection in Low-Resource Environments\n\nThis research will develop a few-shot learning framework for object detection in scenarios with limited labeled data. We will leverage a transformer-based model pre-trained on a large dataset and fine-tune it on a small set of annotated images, focusing on robustness to variations in lighting and background. We will evaluate performance using metrics like mAP (mean Average Precision) and precision@k, comparing against a baseline model trained on the entire dataset.",
      "[HCI] Personalized Embodied Feedback for Navigation Assistance\n\nThis research explores the integration of haptic feedback into a mobile navigation app to provide users with more intuitive and personalized guidance. We will develop a system that uses subtle vibrations to indicate the direction of movement and potential obstacles, tailored to the user\u2019s gait and preferred navigation style. The system will be evaluated through user studies measuring task completion time, error rates, and subjective ratings of comfort and ease of use. Metrics will include frequency of successful navigation and user reported feelings of confidence.",
      "[NLP] Sentiment-Aware Dialogue Summarization for User Engagement\n\nThis research investigates a method for automatically generating concise summaries of long dialogue transcripts, incorporating sentiment analysis to highlight user engagement and potential areas of interest. We will develop a model that not only extracts key events but also assesses the emotional tone of the user's responses, providing a richer understanding of their satisfaction and intent. Data: Collection of dialogue transcripts from a simulated user base. Evaluation: ROUGE scores, human evaluation of summary quality (engagement, clarity).",
      "[Safety] Explainable AI for Automated Loan Denial Decisions\n\nThis research focuses on developing methods to provide transparency and justification for automated loan denial decisions, addressing concerns about fairness and potential discrimination. We will build a system that analyzes loan application data (including applicant demographics, credit history, and income) and generates a detailed, human-readable explanation of the factors contributing to the denial, using techniques like rule-based reasoning and potentially incorporating fairness metrics. Evaluation will involve comparing the system\u2019s explanations to those provided by human loan officers and assessing their accuracy and comprehensibility.",
      "[NLP] Personalized Narrative Generation for User Engagement\n\nThis research will develop a system that generates unique, personalized narratives tailored to individual user preferences and emotional states, using a combination of sentiment analysis and reinforcement learning. The system will analyze user activity and emotional responses to dynamically adjust the narrative's tone, complexity, and content, aiming to increase user engagement and satisfaction.",
      "[NLP] Interactive Visual Storytelling with Emotionally Aware Agents\n\nThis research will develop an interactive storytelling system where an agent responds to user gaze and emotional cues, dynamically adjusting the narrative\u2019s tone and complexity to enhance engagement and emotional impact. The system will utilize a combination of visual scene description, sentiment analysis, and reinforcement learning to create a personalized and responsive storytelling experience. Evaluation will be based on user engagement metrics (time spent, completion rate) and subjective ratings of emotional response.",
      "[NLP] Knowledge Graph Construction from Dialogue Data for Enhanced Question Answering\n\nThis research aims to automatically build and refine knowledge graphs from conversational data, leveraging a transformer-based model to identify entities, relationships, and events within dialogue turns. The system will be evaluated on benchmark question answering datasets using metrics like precision, recall, and F1-score, focusing on the accuracy of knowledge graph completion and reasoning.",
      "[NLP] Contextual Sentiment Analysis of Scientific Literature for Accelerated Discovery\n\nThis research investigates the use of a fine-tuned transformer model to automatically analyze scientific publications and identify key concepts, relationships, and potential research directions. The model will be trained on a corpus of peer-reviewed papers across various disciplines, focusing on identifying emerging themes and highlighting areas of active investigation. Evaluation will be based on precision and recall of relevant concepts, as well as the coherence and readability of the identified insights."
    ],
    [
      "[NLP] Adversarial Training for Robustness in Question Answering Systems\nThis research explores adversarial training techniques to enhance the robustness of question answering (QA) systems against adversarial examples \u2013 subtly modified inputs designed to mislead the model. The system will be trained on a dataset of QA pairs, and adversarial examples will be generated using techniques like paraphrasing and synonym substitution. Evaluation will be based on accuracy on a held-out set of adversarial examples, measuring the model\u2019s resilience to these perturbations.",
      "[HCI] Personalized Gesture Recognition for Assistive Technology \u2013 Enhanced Interaction with Smart Home Devices\n\nThis research will develop a system that utilizes computer vision and machine learning to accurately recognize and interpret user gestures for controlling smart home devices (e.g., lights, thermostats, appliances). The system will leverage a combination of gesture tracking and contextual awareness to provide intuitive and efficient control, adapting to individual user preferences and routines. Evaluation will involve user testing with individuals with varying levels of dexterity and using a set of standardized gesture recognition benchmarks.",
      "[Cognitive Science] Exploring the Role of Implicit Social Evaluation in Episodic Memory Consolidation \u2013 A Longitudinal Study\n\nThis research will conduct a longitudinal study examining the impact of repeated implicit social evaluation on episodic memory consolidation. We will use fMRI to assess neural activity during simulated social interactions, tracking changes in brain regions associated with reward processing and social cognition. The goal is to determine if repeated implicit evaluations of a person\u2019s behavior strengthen the encoding of relevant episodic memories, leading to improved recall and a more robust understanding of how social evaluation shapes memory formation. Data will include behavioral measures of social evaluation (e.g., facial expressions, verbal comments) and fMRI data capturing neural responses to simulated social interactions.",
      "[NLP] Personalized Emotional Response Adaptation for Mental Health Support Chatbots",
      "[NLP] Interactive Storytelling with Dynamic Character Alignment\nThis research investigates a system that dynamically aligns character personalities and motivations within interactive storytelling experiences, adapting to user choices in real-time. We will develop a model that uses reinforcement learning to optimize character behavior based on user feedback and narrative events, enhancing engagement and creating a more immersive experience. Data will include user choices, narrative events, and explicit feedback on character alignment. Evaluation will be based on user engagement metrics (time spent, completion rate) and subjective ratings of character believability and emotional impact.",
      "[Vision] Embodied Dialogue Understanding with Action Prediction\n\nThis research explores the integration of action prediction models with visual grounding to enhance dialogue understanding, particularly in scenarios involving physical actions or interactions. We will train a model to predict the user\u2019s intended action based on visual cues, allowing the system to better anticipate and respond to their actions, leading to more natural and efficient conversations. Evaluation will be based on metrics like task completion rate and user satisfaction.",
      "[NLP] Contextualized Dialogue State Tracking with Attention\n\nThis research explores a novel approach to dialogue state tracking that leverages attention mechanisms to dynamically weight the importance of different contextual cues during response generation. It builds upon the existing work of incorporating visual cues into dialogue understanding, but instead of relying solely on facial expressions, it focuses on analyzing body posture and gestures to refine the model\u2019s understanding of the user\u2019s emotional state and intent. We will evaluate the model\u2019s performance on a benchmark dataset of multi-turn conversations, measuring metrics such as coherence, relevance, and user satisfaction.",
      "[NLP] Adaptive Knowledge Graph Refinement for Scientific Hypothesis Generation",
      "[NLP] Dynamic Persona Generation for Counter-Narrative Response in Social Media \u2013 A Multi-Agent System\nThis research proposes a system that utilizes a multi-agent approach to generate dynamic personas for counter-narratives in social media, responding to user-generated content. The system will leverage a large dataset of social media posts and automatically generate personas representing opposing viewpoints, then dynamically adjust these personas based on user engagement to create a more effective counter-narrative. Evaluation will be based on user sentiment analysis of the counter-narrative and a measure of engagement (e.g., shares, comments).",
      null
    ],
    [
      "[NLP] Personalized Emotional Response Generation for Interactive Storytelling\n\nThis research explores the use of a fine-tuned transformer model to generate emotionally nuanced responses within interactive storytelling platforms. The model will be trained on a dataset of narrative text and associated emotional labels, allowing it to adapt its responses to the user's emotional state and the story's context. Evaluation will be based on user ratings of emotional engagement and coherence within the narrative.",
      "[Safety] AI-Powered Contextual Risk Assessment for Emergency Response \u2013 Integrating Social Media and Sensor Data\n\nThis research will develop an AI system that analyzes real-time social media data (e.g., posts, hashtags) and sensor data (e.g., traffic, pedestrian movement) to provide contextual risk assessments for emergency responders, considering the social and physical environment. The system will leverage a transformer model to identify potential hazards and prioritize response efforts, evaluating effectiveness through a metric of reduced response times and improved situational awareness. Data will include social media posts, traffic sensor data, and emergency call logs.",
      null,
      "[NLP] Visual-Textual Sentiment Alignment for Enhanced Dialogue Quality\n\nThis research explores how visual cues (e.g., facial expressions in videos, objects in images) can be integrated with textual dialogue to improve the coherence and emotional resonance of conversations. We will develop a model that analyzes both the text and visual data to predict the user's emotional state and adjust the dialogue accordingly, leveraging a transformer model trained on paired visual and textual data. We will evaluate the model\u2019s performance using metrics like coherence score and user ratings of emotional engagement.",
      "[NLP] Explainable AI for Medical Image Diagnosis\nThis research investigates methods to provide transparent and interpretable explanations for medical image diagnosis decisions, enabling clinicians to understand *why* a model made a particular prediction. We will explore techniques like attention visualization and counterfactual explanations, evaluating their impact on clinician trust and diagnostic accuracy. We will use a dataset of chest X-rays and train a model to diagnose pneumonia, focusing on the model's reasoning process.",
      "[NLP] Contextualized Sentiment Analysis for Scientific Report Generation\n\nThis research aims to develop a system that automatically generates concise and informative summaries of scientific reports, incorporating contextual sentiment analysis to ensure the report accurately reflects the author's intended message and audience. We will use a transformer-based model fine-tuned on a dataset of scientific reports and their associated sentiment scores. Evaluation will be based on human assessment of report clarity, accuracy, and persuasiveness, as well as automated metrics like ROUGE and BLEU for summarization quality.",
      "[NLP] Interactive Storytelling with Dynamic Character Adaptation using Transformer Networks\n\nThis research explores the integration of transformer networks to dynamically adapt character personalities and storylines within interactive storytelling experiences. The system will utilize a pre-trained transformer model to generate character dialogue and actions, with the network learning to adjust the character\u2019s emotional state and behavior based on user feedback and contextual cues. Evaluation will be based on user engagement metrics (e.g., time spent, completion rate) and subjective ratings of narrative coherence and emotional impact.",
      "[HCI] Personalized Embodied Storytelling through Dynamic Narrative Adaptation\n\nThis research explores how to dynamically adjust the narrative structure and emotional tone of an interactive story based on user emotional responses, leveraging a transformer model to generate branching storylines and adapt to user feedback. It will utilize a dataset of user-generated stories and emotional data, evaluating engagement metrics (e.g., time spent, emotional ratings) and subjective user experience (e.g., perceived narrative coherence).",
      "[NLP] Interactive Emotional Simulation with Adaptive Narrative Coherence\n\nThis research explores the development of an interactive narrative simulation system that dynamically adjusts the emotional tone and narrative coherence based on user responses, aiming to enhance engagement and emotional processing. The system will utilize a transformer model to generate branching storylines and dynamically adjust character responses, incorporating a reinforcement learning component to optimize for user emotional feedback. Evaluation will involve subjective ratings of emotional impact, narrative coherence, and user engagement.",
      null
    ],
    [
      "[NLP] Knowledge Graph Enhanced Sentiment Analysis for Product Reviews\n\nThis research will develop a knowledge graph-enhanced sentiment analysis model that leverages product reviews to understand the underlying features and attributes of products. The model will integrate information from product descriptions, user reviews, and expert knowledge to provide a richer understanding of product sentiment, improving the accuracy of sentiment analysis and enabling more nuanced product feedback. Evaluation will involve human evaluation of the model\u2019s ability to identify key product features driving sentiment.",
      "[NLP] Personalized Dialogue Generation for Mental Health Support Chatbots\n\nThis research will develop a dialogue generation model specifically tailored for mental health chatbots, focusing on empathetic and supportive responses. The model will utilize a transformer architecture trained on a dataset of therapeutic conversations, incorporating reinforcement learning to optimize for user engagement and emotional well-being. Evaluation will be based on user surveys assessing perceived empathy, helpfulness, and overall satisfaction.",
      "[NLP] Knowledge Graph Completion with Adversarial Training\nThis research explores the use of adversarial training to improve the accuracy and robustness of knowledge graph completion models. It will focus on training a model to predict missing relationships within a large knowledge graph, incorporating a novel adversarial loss function that encourages the model to produce plausible but incorrect predictions. Evaluation will be based on metrics like Mean Rank and Exact Match, comparing the model\u2019s performance to existing knowledge graph completion methods.",
      "[NLP] Explainable Sentiment Analysis for Customer Service Interactions\n\nThis research investigates the development of an explainable sentiment analysis model specifically tailored for analyzing customer service interactions (e.g., chat logs, call transcripts). The model will leverage attention mechanisms to highlight the parts of the text that contribute most to the sentiment, and will provide insights into *why* a customer is expressing a particular sentiment. Data will be collected from a simulated customer service platform, and evaluation will be based on metrics like precision, recall, and F1-score, alongside human evaluation of the model\u2019s explanations.",
      "[NLP] Personalized Dialogue Generation with Contextual Memory Networks\n\nThis research explores the integration of contextual memory networks with personalized dialogue generation models to create more engaging and empathetic conversational experiences. We will train a model to dynamically adapt its responses based on the user's past interactions and emotional state, enhancing the sense of rapport and reducing frustration. Evaluation will be based on user satisfaction scores, conversation length, and the frequency of positive feedback.",
      "[HCI] Embodied Conversational Agents for Mental Health Support",
      "[NLP] Personalized Storytelling with Dynamic Narrative Structure\n\nThis research explores a system that dynamically adjusts the narrative structure of a story based on the user's emotional state detected through physiological data (e.g., heart rate variability). The system will utilize a wearable sensor to collect physiological data and a neural network to analyze the data and generate a branching narrative with increasing levels of suspense, humor, or emotional resonance. Evaluation will be based on user engagement (measured through story completion rate and subjective ratings of emotional impact), and the accuracy of the physiological state prediction.",
      "[NLP] Interactive Narrative Coherence with Ethical Constraints\n\nThis research explores a system that dynamically adjusts the narrative coherence and ethical constraints of interactive stories, leveraging a transformer model to ensure consistent adherence to predefined moral guidelines and preventing harmful or biased storylines. It will utilize a dataset of stories annotated with ethical principles and evaluate the system\u2019s ability to maintain coherence and avoid problematic content through automated analysis and human feedback.",
      "[NLP] Personalized Emotional Storytelling with Adaptive Character Reactions\nThis research investigates the use of a transformer model to dynamically adjust the emotional responses and dialogue of virtual characters based on user input and observed emotional states, creating a more engaging and empathetic experience. We will evaluate the system\u2019s effectiveness through user surveys and physiological data analysis, focusing on improved user engagement and perceived emotional connection. Neighbor (6, 9) [score=0.88, last_updated=7] provides a good starting point for emotional simulation, and this adaptation will build upon its ability to respond to nuanced user cues.",
      "[NLP] Interactive Narrative Generation with Dynamic Character Motivation\nThis research explores the integration of reinforcement learning with a narrative generation model to create interactive stories where character motivations dynamically shift based on player choices and observed emotional responses. We will train a model to generate branching narratives with evolving character goals, utilizing a combination of reinforcement learning and emotional state detection."
    ],
    [
      "[NLP] Explainable Sentiment Analysis of Online Reviews with Attention Mechanisms\nThis research investigates the use of attention mechanisms within transformer-based models to improve the explainability of sentiment analysis performed on online reviews. It will focus on identifying the specific parts of the review text that contribute most to the overall sentiment, allowing for a more granular understanding of why a review is positive or negative. Evaluation will be based on human evaluation of the model\u2019s explanations, measuring their coherence, relevance, and faithfulness to the review text.",
      null,
      "[NLP] Dynamic Sentiment Scoring for Customer Support Tickets\nThis research investigates a system that dynamically adjusts sentiment scores for customer support tickets based on the *context* of the conversation, moving beyond simple keyword matching. It will utilize a transformer model trained on a large dataset of labeled tickets, incorporating contextual cues like topic, sentiment of previous responses, and user history to improve the accuracy of sentiment analysis. The evaluation will measure the improvement in prediction accuracy compared to a baseline system.",
      "[HCI] Personalized Emotional Response Mapping for Virtual Assistants\n\nThis research explores the design of a system that allows virtual assistants to dynamically map the emotional state of a user based on their verbal and non-verbal communication, providing a more empathetic and responsive interaction. The system will utilize a combination of speech emotion recognition (SER) and facial expression analysis, trained on a diverse dataset of user interactions. Evaluation will be based on user satisfaction ratings and a subjective measure of perceived empathy.",
      "[Cognitive Science] Exploring the Impact of Implicit Bias on Collaborative Problem-Solving in Virtual Teams\n\nThis research investigates how implicit biases \u2013 unconscious stereotypes \u2013 affect team dynamics and collaborative problem-solving in virtual teams, specifically focusing on communication patterns and decision-making processes. I will develop a simulation model that incorporates implicit bias detection and mitigation strategies, evaluating their impact on team performance and conflict resolution. The model will utilize a combination of sentiment analysis and behavioral observation to assess team communication and identify potential biases. Evaluation will be based on team task completion rates, conflict resolution effectiveness, and subjective team member perceptions of fairness.",
      "[HCI] Interactive Narrative Simulation for Trauma Recovery\n\nThis research develops an interactive narrative experience designed to help individuals process traumatic memories through a carefully constructed, branching story. The system will utilize NLP to generate dynamic responses based on user choices, incorporating elements of cognitive behavioral therapy (CBT) principles. Evaluation will be based on standardized trauma assessment tools and subjective user reports of emotional regulation and narrative engagement.",
      "[Vision]  Explainable AI (XAI) for Medical Image Diagnosis using Attention Maps\n\nThis research explores the application of attention maps derived from convolutional neural networks (CNNs) to provide explainable insights into the diagnostic reasoning of medical image analysis models. We will develop a method to visualize and interpret the attention weights assigned to different regions of an image, allowing clinicians to understand which features the model is focusing on when making a diagnosis. Evaluation will be based on human evaluation of the clarity and usefulness of the explanations, as well as quantitative metrics like accuracy and sensitivity of the model\u2019s predictions.",
      null,
      "[NLP] Interactive Narrative Simulation with Dynamic Character Alignment\n\nThis research investigates the development of a system that allows for the creation of interactive narratives where character alignment and emotional consistency are dynamically adjusted based on user feedback and contextual information. We will use a reinforcement learning approach to train a model to predict and influence character behavior, incorporating a user-defined emotional profile and a real-time analysis of narrative events. Evaluation will be based on user ratings of narrative coherence, emotional engagement, and character believability, measured using a Likert scale.",
      "[NLP] Dynamic Persona Generation for Scientific Communication\nThis research develops a system that generates dynamically evolving personas for scientific researchers, adapting their communication style and expertise based on the audience and context. It leverages a transformer-based model fine-tuned on a corpus of scientific papers and expert interviews, evaluating its effectiveness through simulated audience engagement metrics and expert feedback."
    ],
    [
      null,
      "[HCI] Context-Aware Navigation Assistance with Predictive Vibration Feedback\n\nThis research develops a mobile navigation app that dynamically adjusts route recommendations based on the user\u2019s observed gait and predicted movement patterns, utilizing subtle vibration feedback to provide a more intuitive and personalized experience. The system will integrate accelerometer and gyroscope data to forecast the user\u2019s next steps, offering proactive guidance and minimizing disorientation. Evaluation will involve user studies measuring task completion time, error rates, and subjective comfort ratings. Metrics will include frequency of successful navigation and user reported feelings of confidence.",
      "[HCI] Personalized Embodied Navigation via Predictive Vibration Mapping\n\nThis research explores the integration of haptic feedback into a mobile navigation app to provide users with more intuitive and personalized guidance. We will develop a system that uses subtle vibrations to indicate the direction of movement and potential obstacles, tailored to the user\u2019s gait and preferred navigation style. The system will leverage gait data collected through IMUs and user feedback on navigation accuracy. Evaluation will be based on subjective user ratings of navigation clarity and perceived ease of use, as well as objective metrics like time to reach destination and error rate.",
      null,
      "[NLP] Adaptive Character Voice Synthesis for Emotional Expression",
      "[NLP] Personalized Emotional Feedback System for Creative Writing\n\nThis research will develop a system that analyzes a writer\u2019s creative text \u2013 including prose, poetry, and scripts \u2013 to provide personalized feedback on emotional tone and engagement, using a transformer model to identify and quantify emotional states. Evaluation will be based on subjective human ratings of emotional impact and stylistic coherence, measured using a Likert scale.",
      "[NLP] Knowledge Graph Completion with Adaptive Reasoning\n\nThis research investigates the use of knowledge graph completion (KGC) techniques augmented with adaptive reasoning to improve the accuracy and robustness of question answering systems. Current KGC methods often rely on fixed reasoning rules, failing to handle complex, multi-hop queries. We propose a system that dynamically adjusts the reasoning path based on the uncertainty in the knowledge graph and the user's question, leveraging a probabilistic reasoning framework. Evaluation will be conducted on benchmark question answering datasets, measuring accuracy and efficiency.",
      null,
      null,
      "[HCI] Contextual Knowledge Graph Construction for Interactive Storytelling\n\nThis research investigates the design of a system that dynamically constructs and updates a knowledge graph representing a user's evolving narrative preferences and world knowledge during an interactive storytelling experience. We will develop a system that leverages user feedback and contextual data to automatically generate and refine a personalized knowledge graph, enhancing engagement and immersion. Data will include user choices, narrative events, and explicit feedback. Evaluation will be based on user engagement metrics (time spent, number of choices), subjective ratings of narrative coherence and interest, and a measure of knowledge graph completeness."
    ],
    [
      "[Cognitive Psychology] Dynamic Route Adaptation via Predictive Attention Modeling\n\nThis research investigates how visual attention shifts during route navigation, and how this shifts can be leveraged to improve route adherence and reduce cognitive load. It will develop a system that analyzes visual attention patterns (using eye-tracking) and dynamically adjusts route recommendations to capitalize on periods of heightened attention, promoting more consistent route following. Data will include eye-tracking, route tracking, and user-reported attention levels. Evaluation will be based on subjective user ratings of route adherence and perceived cognitive effort.",
      "[Safety] Autonomous Vehicle Route Optimization with Predictive Risk Assessment\n\nThis research explores the integration of predictive risk assessment models into autonomous vehicle route planning, focusing on identifying and mitigating potential hazards based on the user\u2019s observed gait and environmental context. It will develop a system that analyzes accelerometer and gyroscope data to predict potential collisions and adjust route parameters accordingly, enhancing safety and reducing the risk of accidents. Evaluation will involve simulated driving scenarios and real-world testing with a focus on collision avoidance and passenger safety.",
      "[NLP] Dynamic Route Adaptation via Predictive Vibration Mapping and Sensor Fusion\n\nThis research investigates a system that dynamically adapts route recommendations in real-time by fusing predictive vibration mapping with data from a smartphone\u2019s accelerometer and gyroscope. The system will learn user gait patterns and predict navigational challenges, proactively adjusting route suggestions to minimize disorientation. Data will include accelerometer and gyroscope readings, along with user feedback on route choices. Evaluation will be based on user satisfaction (measured via a post-route survey) and the accuracy of route adjustments.",
      "[Vision] Interactive Visual-Textual Crisis Detection with Adaptive Attention\n\nThis research explores a system that dynamically adjusts the level of attention given to visual and textual cues during crisis detection, leveraging a transformer model to prioritize the most relevant information. The system will utilize a dataset of social media posts and corresponding images, and evaluate performance using a custom metric combining precision and recall on crisis prediction tasks.",
      "[NLP] Dynamic Crisis Prediction via Multi-Modal Sentiment Fusion\nThis research will develop a system that predicts potential crises by fusing sentiment analysis from social media posts with visual cues (e.g., image analysis) and textual context, leveraging a transformer model to dynamically adjust the weighting of each modality. Evaluation will be based on precision and recall for identifying emerging crisis indicators, as well as a user-defined metric of time to detection.",
      "[NLP] Adaptive Dialogue System for Mental Health Support - Leveraging Emotional State Recognition and Personalized Response Generation",
      "[NLP] Contrastive Learning for Explainable AI\n\nThis research explores using contrastive learning to improve the explainability of deep learning models by generating synthetic data that highlights the model's decision-making process. It leverages a pre-trained language model to create pairs of inputs and their corresponding explanations, allowing for a more granular understanding of how the model arrives at its predictions. Data: A dataset of image classification tasks with corresponding human-generated explanations. Evaluation:  Metrics like BLEU score and human evaluation of explanation quality.",
      "[HCI] Embodied Navigation Assistant for Mobile Gaming\n\nThis research explores the design of an embodied navigation assistant for mobile games, utilizing a combination of visual SLAM and reinforcement learning to guide players through complex environments. It will focus on creating a system that dynamically adapts to player behavior and environmental changes, providing intuitive and efficient navigation assistance, ultimately enhancing the player experience and reducing frustration. Data will include player movement data, game environment data (e.g., map layouts, obstacles), and metrics such as navigation success rate, time spent navigating, and player satisfaction scores.",
      null,
      "[Safety] Algorithmic Bias Detection in Autonomous Vehicle Perception Systems\n\nThis research will develop a novel framework for detecting and quantifying algorithmic bias in pedestrian detection models used by autonomous vehicles. The framework will leverage a combination of adversarial training and explainable AI (XAI) techniques to identify disparities in detection rates across demographic groups (e.g., based on age, race, and gender). We will evaluate the framework using a publicly available dataset of pedestrian images and metrics such as precision, recall, and F1-score, focusing on identifying patterns indicative of biased model behavior."
    ]
  ]
}